[
  {
    "objectID": "findings.html",
    "href": "findings.html",
    "title": "Findings",
    "section": "",
    "text": "Your browser does not support the video tag. \n\n\n\n\n\n©Video by Desra\n\n\n\n\n\nMain findings focused on Feature Importance.\n\nBrazil, subsidies and other transfers, and agricultural land were the most significant contributors to deforestation among all variables.\n\n\n\n\n\n\nIn the Random Forest analysis, the feature “Country_Brazil” has high importance, not simply because Brazil has a large forest area, but because its deforestation trends are highly variable and strongly influenced by other factors like agricultural subsidies, political policies, and enforcement of conservation laws. For instance, Brazil experienced a deforestation peak in 2004 when 27,772 km² of forests were cleared (equivalent to the size of Massachusetts), followed by a decline during years with stricter policies (Silva Junior et al. 2021). This variability in deforestation rates makes Brazil-specific data critical in understanding global deforestation trends. Similarly, countries like Paraguay and Tanzania also rank highly due to their distinct patterns, such as agricultural expansion or population pressures, which uniquely influence their forest loss dynamics.\n\nBy defintion, Subsidies and Other Transfers benefits include all unrequited, nonrepayable transfers on current account to private and public enterprises; grants to foreign governments, international organizations, and other government units; and social security, social assistance benefits, and employer social benefits in cash and in kind. According to Amaglobeli et al. (2024), Agricultural producer subsidies are prevalent, large, and deployed to achieve diverse and, at times, overlapping policy objectives. Among countries accounting for 90 percent of global GDP, food and agriculture subsidies amount to 0.3–0.7 percent of GDP over the past decade and a half. As highlighted by Damania et al. (2023), highlighted inefficiency of agricultural and timber subsidies. Between 2016 and 2018, $635 billion per year (equals approximately 0.9 percent of GDP and nearly one-fifth of agricultural value added for these countries) was given as support to agriculture in 84 countries. 71% of this support went directly to farmers or producers, mainly in ways that encouraged them to produce more or use certain inputs, which can influence their decisions on what and how much to produce. This type of support often encourage unsustainable practices, such as excessive use of chemical fertilizers and pesticides, which lead to greenhouse gas emissions, land degradation, and biodiversity loss. Similarly, timber subsidies contribute to overharvesting, illegal logging, and forest degradation. They distort markets by making sustainable forest management less competitive than subsidized, unsustainable logging.\n\nThe feature Agricultural Land (sq. km) emerges as one of the most significant contributors to deforestation in the feature importance analysis. This result is in line with finding from Hosonuma et al. (2012). Commercial agriculture is the most important driver of deforestation, followed by subsistence agriculture. Their study showed agriculture alone causes 73% of all deforestation. 40% of deforestation and most prominent in the early-transition phase. The other important land use is local/subsistence agriculture, which is related to 33% of deforestation.\n\nOther factors that stand out in the analysis are governance and economic indicators, which reveal intriguing relationships with deforestation. For instance, control of corruption shows a notable connection to deforestation, suggesting that governance quality significantly influences how natural resources are managed. In regions with poor governance and high corruption, illegal logging, weak enforcement of environmental regulations, and unsustainable land-use practices are more prevalent, exacerbating deforestation rates. Conversely, better governance often correlates with stronger protections and more sustainable practices.\n\nAnother compelling factor is debt service on external debt, which indicates the economic pressures faced by nations. When a country allocates a significant portion of its resources toward debt repayment, it may prioritize short-term economic gains, such as expanding agricultural exports or extracting natural resources, to generate revenue. This often results in deforestation as forests are cleared to make way for cash crops or logging operations. Together, these governance and economic factors underline the complex, interconnected pressures that drive deforestation, pointing to the need for policies that address systemic issues like corruption and economic vulnerability to protect forests effectively.\n\n\n\n\n\n\nContemplation\n\nOver time, the theory of deforestation has evolved, moving from simplistic explanations centered on population growth and agricultural expansion to more nuanced, multidimensional frameworks. Earlier models, like those discussed by Angelsen and Kaimowitz (1999), focused on economic drivers and agent-based decision-making, emphasizing variables such as land-use choices, macroeconomic pressures, and policy instruments. Recent research has expanded these perspectives by incorporating the roles of governance, global trade, climate change, and spatial dynamics. Studies now recognize deforestation as a complex phenomenon influenced by intertwined local and global factors, such as subsidies driving unsustainable agricultural practices, corruption weakening forest protections, and international markets shaping land-use patterns. This evolution reflects a shift toward systems-level thinking, which integrates biophysical, socioeconomic, and governance dimensions. Thus, while foundational theories remain relevant, contemporary approaches offer a deeper, more holistic understanding of deforestation, better equipping policymakers to address its underlying and immediate causes in an increasingly interconnected world.\n\n\n\n\nWhat we are doing to the forests of the world is but a mirror reflection of what we are doing to ourselves and to one another. ~ Mahatma Gandhi\n\n\n\n\n\nAdditional discussions\n\nPrediction\nAlthough my analysis included predicting deforestation using socioeconomic factors with a Random Forest model, I believe that relying solely on these factors for such predictions may lack a solid logical foundation. Socioeconomic variables, while insightful, typically act as indirect drivers or proxies rather than immediate causes of deforestation. This perspective aligns with the framework proposed by Angelsen and Kaimowitz (1999), my main reference, which emphasizes the importance of analyzing deforestation through a more comprehensive approach. Their framework suggests considering the magnitude and location of deforestation, the agents involved, the variables influencing their choices, the decision parameters of these agents, as well as macroeconomic variables and policy instruments. A logical approach, as outlined in their work, involves understanding deforestation at three interconnected levels: sources, immediate causes, and underlying causes. By focusing only on socioeconomic factors, key dimensions such as the direct actions of deforestation agents (e.g., farmers or loggers), the biophysical constraints, and the specific policy environment might be overlooked.\n\nOptimization\nThe initial Random Forest model achieved an R² score of 0.67 on the testing dataset, indicating that 67% of the variance in the target variable was explained by the model. Using 3-fold cross-validation, the R² scores varied between 0.85, 0.71, and 0.56, with an average score of 0.71 and a standard deviation of 0.12, highlighting moderate variability in model performance across different folds. After optimizing the model using GridSearchCV, the testing R² score remained unchanged at 0.67. However, the 3-fold cross-validation scores showed slight improvement, with individual scores of 0.86, 0.74, and 0.56. This resulted in an increased average cross-validation score of 0.72, while the standard deviation remained at 0.12.\n\n\n\n\n\nReferences\n\nAmaglobeli, D. (2024). Agricultural producer subsidies. IMF Notes, 2024(002), 1. https://doi.org/10.5089/9798400285950.068.\n\nAngelsen, A., & Kaimowitz, D. (1999). Rethinking the Causes of Deforestation: Lessons from Economic Models. The World Bank Research Observer, 14(1), 73–98. https://doi.org/10.1093/wbro/14.1.73.\n\nDamania, R., Balseca, E., De Fontaubert, C., Gill, J., Kim, K., Rentschler, J., Russ, J., & Zaveri, E. (2023). Detox development. https://doi.org/10.1596/978-1-4648-1916-2.\n\nHosonuma, N., Herold, M., De Sy, V., De Fries, R. S., Brockhaus, M., Verchot, L., Angelsen, A., & Romijn, E. (2012). An assessment of deforestation and forest degradation drivers in developing countries. Environmental Research Letters, 7(4), 044009. https://doi.org/10.1088/1748-9326/7/4/044009.\n\nSilva Junior, C. H. L., Pessôa, A. C. M., Carvalho, N. S., et al. (2021). The Brazilian Amazon deforestation rate in 2020 is the greatest of the decade. Nature Ecology & Evolution, 5(2), 144–145. https://doi.org/10.1038/s41559-020-01368-x."
  },
  {
    "objectID": "thoughts.html",
    "href": "thoughts.html",
    "title": "Thoughts",
    "section": "",
    "text": "©Photo by Desra\n\n In 1999, researchers from the World Bank published an article titled “Rethinking the causes of deforestation: lesson from economic models”. This article synthesized the causes of deforestation based on hundreds of economic models available at that time. They highlighted a logical approach to analyzing deforestation at three different levels: sources (small farmers, loggers, etc.), immediate causes (prices, wages, technology, accessibility, etc.), and underlying causes (population, economic growth). A clear distinction among the three levels was based on the scale, from micro to macro influences. The findings showed only weak support for the thesis that population growth and poverty are driving forces of deforestation. Economic growth often drives deforestation by influencing higher agricultural and timber prices, while lower timber prices tend to reduce logging and agricultural encroachment. The tenure thesis suggests that secure land tenure can influence deforestation by incentivizing forest clearing. The intensification thesis revealed a mixed effect, as agricultural advancements may either exacerbate or alleviate deforestation.\nInspired by this article, I set out to “re-rethink” several variables that influence deforestation. I used the World Bank’s data API, a Python library that provides access to a wide range of global development data. This allowed me to analyze updated World Bank datasets using machine learning and examine the impact of various variables (see the list below) on deforestation.\nThis study utilized the Random Forest method to analyze the impact of various key drivers on deforestation. The main findings focused on Feature Importance. The process was carried out in the following steps:\n\n\n\n\n\n\n A total of 65 variables were selected and classified into 10 topic groups, including:\nAgriculture and land use\nAgricultural land (sq. km)\nForest area (% of land area)\nAgricultural land (% of land area)\nArable land (hectares)\nPermanent cropland (% of land area)\nForest area (sq. km)\nUrban land area (sq. km)\nCereal production (metric tons)\nCrop production index (2014-2016 = 100)\nFertilizer consumption (% of fertilizer production)\n\nEconomy\nAgriculture, forestry, and fishing, value added (% of GDP)\nAdjusted savings: net forest depletion (current USD)\nForest rents (% of GDP)\nGDP growth (annual %)\nAgricultural raw materials imports (% of merchandise imports)\nImport value index (2015 = 100)\nAgricultural raw materials exports (% of merchandise exports)\nTrade in services (% of GDP)\nPrimary income payments (BoP, current USD)\nTravel services (% of service imports, BoP)\nExports of goods and services (BoP, current USD)\nMarket capitalization of listed domestic companies (current USD)\nExternal debt stocks, total (DOD, current USD)\nUse of IMF credit (DOD, current USD)\nDebt service on external debt, total (TDS, current USD)\nMultilateral debt service (TDS, current USD)\nBorrowers from commercial banks (per 1,000 adults)\nNet domestic credit (current LCU)\nNet foreign assets (current LCU)\nConsumer price index (2010 = 100)\nTaxes on exports (current LCU)\nTaxes on goods and services (current LCU)\nTaxes on international trade (current LCU)\nSubsidies and other transfers (current LCU)\nLead time to export, median case (days)\nGDP (current USD)\n\nEducation\nLiteracy rate, adult total (% of people ages 15 and above)\nSchool enrollment, primary (% gross)\nSchool enrollment, secondary (% gross)\n\nEmployment\nChild employment in agriculture (% of economically active children ages 7-14)\nEmployment in agriculture (% of total employment) (modeled ILO estimate)\nSelf-employed, total (% of total employment) (modeled ILO estimate)\nLabor force, total\n\nEnergy\nFossil fuel energy consumption (% of total)\nEnergy use (kg of oil equivalent per capita)\n\nHealth\nPrevalence of underweight, weight for age (% of children under 5)\nPrevalence of undernourishment (% of population)\n\nInequality\nPoverty headcount ratio at D2.15 a day (2017 PPP) (% of population)\nGini index\n\nInstitutional quality\nGovernment Effectiveness: Estimate\nRegulatory Quality: Estimate\nControl of Corruption: Estimate\n\nPopulation\nPopulation density (people per sq. km of land area)\nPopulation growth (annual %)\nPopulation, total\nRural population\nRural population growth (annual %)\nRural population (% of total population)\nUrban population growth (annual %)\nUrban population (% of total population)\nRural land area (sq. km)\nHuman capital index (HCI) (scale 0-1)\nRail lines (total route-km)\n\nStability\nPolitical Stability and Absence of Violence/Terrorism: Estimate\nInternally displaced persons, total displaced by conflict and violence (number of people)\n\n\nReference\nAngelsen, A., & Kaimowitz, D. (1999). Rethinking the Causes of Deforestation: Lessons from Economic Models. The World Bank Research Observer, 14(1), 73–98. https://doi.org/10.1093/wbro/14.1.73."
  },
  {
    "objectID": "analysis/Final_project.html",
    "href": "analysis/Final_project.html",
    "title": "Analysis",
    "section": "",
    "text": "Re-rethinking the causes of deforestation: does the theory evolve? by Desra Arriyadi"
  },
  {
    "objectID": "analysis/Final_project.html#environment-setup",
    "href": "analysis/Final_project.html#environment-setup",
    "title": "Analysis",
    "section": "Environment setup",
    "text": "Environment setup\nThis section sets up the Python environment by importing essential libraries like pandas, numpy, sklearn, and other libraries.\nPackages like wbgapi (for accessing World Bank data) and geoviews (for geospatial visualization) are installed to handle data processing and visualization tasks.\n\n\nCode\n%%capture\nfrom google.colab import drive\ndrive.mount('/content/drive')\n\n\n\n\nCode\n%%capture\n%cd /content/drive/MyDrive/Colab Notebooks\n\n\n\n\nCode\n!pip install --quiet wbgapi\n!pip install --quiet hvplot\n!pip install --quiet geoviews cartopy\n\n\n\n\nCode\nimport wbgapi as wb\nimport pandas as pd\nimport numpy as np\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import LinearSegmentedColormap\nimport seaborn as sns\nimport altair as alt\nimport requests\nimport folium\nfrom folium import Choropleth\nimport holoviews as hv\nimport hvplot.pandas\nfrom vega_datasets import data\n\n# Models\nfrom sklearn.ensemble import RandomForestRegressor\n\n# Model selection\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n\n# Pre-Processing\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\n\n# Pipelines\nfrom sklearn.pipeline import make_pipeline\n\n# Metrics\nfrom sklearn.metrics import recall_score, r2_score\n\npd.set_option('display.max_columns',500)\npd.set_option('display.max_rows', 100)\nhv.extension(\"bokeh\")"
  },
  {
    "objectID": "analysis/Final_project.html#data-loading",
    "href": "analysis/Final_project.html#data-loading",
    "title": "Analysis",
    "section": "Data loading",
    "text": "Data loading\nFilter out non-country entities (like regions or continents) from the World Bank data. The allCountry DataFrame initially includes all entities, but only rows with valid country-level data are retained by dropping NaN values and extracting the country id into allCountryList.\n\n\nCode\n# Select only ID countries by excluding region/group/etc\nallCountry = wb.economy.DataFrame()\nallCountryList = allCountry.dropna().reset_index()['id'].tolist()\n\n\nData is retrieved for specific variables relevant to deforestation, such as forest area, agricultural land, economy, and other variables.\n\n\nCode\nallVariables =['AG.LND.AGRI.K2',\n'AG.LND.FRST.ZS',\n'AG.LND.AGRI.ZS',\n'AG.LND.ARBL.HA',\n'AG.LND.CROP.ZS',\n'AG.LND.FRST.K2',\n'AG.LND.TOTL.UR.K2',\n'AG.PRD.CREL.MT',\n'AG.PRD.CROP.XD',\n'EG.USE.COMM.FO.ZS',\n'EG.USE.PCAP.KG.OE',\n'EN.POP.DNST',\n'GE.EST',\n'NV.AGR.TOTL.ZS',\n'NY.ADJ.DFOR.CD',\n'NY.GDP.FRST.RT.ZS',\n'NY.GDP.MKTP.KD.ZG',\n'PV.EST',\n'RQ.EST',\n'SE.ADT.LITR.ZS',\n'SE.PRM.ENRR',\n'SE.SEC.ENRR',\n'SH.STA.MALN.ZS',\n'SI.POV.DDAY',\n'SI.POV.GINI',\n'SL.AGR.0714.ZS',\n'SL.AGR.EMPL.ZS',\n'SL.EMP.SELF.ZS',\n'SL.TLF.TOTL.IN',\n'SN.ITK.DEFC.ZS',\n'SP.POP.GROW',\n'SP.POP.TOTL',\n'SP.RUR.TOTL',\n'SP.RUR.TOTL.ZG',\n'SP.RUR.TOTL.ZS',\n'SP.URB.GROW',\n'SP.URB.TOTL.IN.ZS',\n'TM.VAL.AGRI.ZS.UN',\n'TM.VAL.MRCH.XD.WD',\n'TX.VAL.AGRI.ZS.UN',\n'VC.IDP.TOCV',\n'AG.CON.FERT.PT.ZS',\n'AG.LND.TOTL.RU.K2',\n'BG.GSR.NFSV.GD.ZS',\n'BM.GSR.FCTY.CD',\n'BM.GSR.TRVL.ZS',\n'BX.GSR.GNFS.CD',\n'CC.EST',\n'CM.MKT.LCAP.CD',\n'DT.DOD.DECT.CD',\n'DT.DOD.DIMF.CD',\n'DT.TDS.DECT.CD',\n'DT.TDS.MLAT.CD',\n'FB.CBK.BRWR.P3',\n'FM.AST.DOMS.CN',\n'FM.AST.NFRG.CN',\n'FP.CPI.TOTL',\n'GC.TAX.EXPT.CN',\n'GC.TAX.GSRV.CN',\n'GC.TAX.INTT.CN',\n'GC.XPN.TRFT.CN',\n'HD.HCI.OVRL',\n'IS.RRS.TOTL.KM',\n'LP.EXP.DURS.MD',\n'NY.GDP.MKTP.CD'\n]\n\n\nThis function process_wb_variables retrieves and processes data from the World Bank API for a list of variables, countries, and years.\nPurpose: Fetch data for specified variables and merge into a single DataFrame for analysis. Process includes data for each variable is fetched and cleaned (resetting index, renaming columns, filtering by countries, and restructuring into long format). Years are standardized as integers. Each variable’s data is stored in a list. All variables’ data are merged into a single DataFrame by country, year, and ID. Error Handling: Logs errors for individual variables and raises an exception if no data is successfully processed. Output: Returns a comprehensive DataFrame (wbData) containing aligned data for all variables, countries, and years.\n\n\nCode\n# Note: range start year to end year-1\ndef process_wb_variables(variables, allCountryList, time_range=range(2000, 2024)):\n    # List to store processed dataframes\n    processed_dfs = []\n\n    # Process each variable\n    for variable in variables:\n        try:\n            # Fetch data\n            dfGetData = wb.data.DataFrame(variable, time=time_range, labels=True)\n\n            # Reset the index to make 'economy' and 'economy_label' as columns\n            dfGetData = dfGetData.reset_index()\n\n            # Rename the columns\n            dfGetData = dfGetData.rename(columns={\n                'economy': 'ID',\n                dfGetData.columns[1]: 'Country'\n            })\n\n            # Filter countries\n            dfGetData = dfGetData[dfGetData['ID'].isin(allCountryList)]\n\n            # Melt the DataFrame\n            melted_df = dfGetData.melt(\n                id_vars=['ID', 'Country'],\n                var_name='year',\n                value_name=variable  # Use variable code as value column name\n            )\n\n            # Convert year to integer\n            melted_df['year'] = melted_df['year'].astype(str).str.replace('YR', '').astype(int)\n\n            # Sort and add to list\n            melted_df = melted_df.sort_values(['ID', 'year'])\n\n            processed_dfs.append(melted_df)\n\n            #print(f\"Processed {variable} successfully\")\n\n        except Exception as e:\n            print(f\"Error processing {variable}: {e}\")\n\n    # Merge all processed dataframes\n    if processed_dfs:\n        # Merge on ID, Country, and year\n        merged_df = processed_dfs[0]\n        for dfGetData in processed_dfs[1:]:\n            merged_df = pd.merge(merged_df, dfGetData, on=['ID', 'Country', 'year'], how='outer')\n\n        return merged_df\n    else:\n        raise ValueError(\"No variables could be processed\")\n\n# Process all variables\nwbData = process_wb_variables(allVariables, allCountryList)\n\n\n\n\nCode\nwbData.round(1)\n\n\n\n  \n    \n\n\n\n\n\n\nID\nCountry\nyear\nAG.LND.AGRI.K2\nAG.LND.FRST.ZS\nAG.LND.AGRI.ZS\nAG.LND.ARBL.HA\nAG.LND.CROP.ZS\nAG.LND.FRST.K2\nAG.LND.TOTL.UR.K2\nAG.PRD.CREL.MT\nAG.PRD.CROP.XD\nEG.USE.COMM.FO.ZS\nEG.USE.PCAP.KG.OE\nEN.POP.DNST\nGE.EST\nNV.AGR.TOTL.ZS\nNY.ADJ.DFOR.CD\nNY.GDP.FRST.RT.ZS\nNY.GDP.MKTP.KD.ZG\nPV.EST\nRQ.EST\nSE.ADT.LITR.ZS\nSE.PRM.ENRR\nSE.SEC.ENRR\nSH.STA.MALN.ZS\nSI.POV.DDAY\nSI.POV.GINI\nSL.AGR.0714.ZS\nSL.AGR.EMPL.ZS\nSL.EMP.SELF.ZS\nSL.TLF.TOTL.IN\nSN.ITK.DEFC.ZS\nSP.POP.GROW\nSP.POP.TOTL\nSP.RUR.TOTL\nSP.RUR.TOTL.ZG\nSP.RUR.TOTL.ZS\nSP.URB.GROW\nSP.URB.TOTL.IN.ZS\nTM.VAL.AGRI.ZS.UN\nTM.VAL.MRCH.XD.WD\nTX.VAL.AGRI.ZS.UN\nVC.IDP.TOCV\nAG.CON.FERT.PT.ZS\nAG.LND.TOTL.RU.K2\nBG.GSR.NFSV.GD.ZS\nBM.GSR.FCTY.CD\nBM.GSR.TRVL.ZS\nBX.GSR.GNFS.CD\nCC.EST\nCM.MKT.LCAP.CD\nDT.DOD.DECT.CD\nDT.DOD.DIMF.CD\nDT.TDS.DECT.CD\nDT.TDS.MLAT.CD\nFB.CBK.BRWR.P3\nFM.AST.DOMS.CN\nFM.AST.NFRG.CN\nFP.CPI.TOTL\nGC.TAX.EXPT.CN\nGC.TAX.GSRV.CN\nGC.TAX.INTT.CN\nGC.XPN.TRFT.CN\nHD.HCI.OVRL\nIS.RRS.TOTL.KM\nLP.EXP.DURS.MD\nNY.GDP.MKTP.CD\n\n\n\n\n0\nABW\nAruba\n2000\n20.0\n2.3\n11.1\n2000.0\nNaN\n4.2\n87.4\nNaN\nNaN\nNaN\nNaN\n503.3\nNaN\n0.0\n13173.8\n0.0\n7.6\nNaN\nNaN\n97.0\n108.3\n93.8\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n1.0\n90588.0\n48268.0\n1.8\n53.3\n0.2\n46.7\n2.9\n206.5\n0.7\nNaN\nNaN\n94.8\n119.0\n77016759.8\n22.6\n1.815620e+09\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n1.478961e+09\n5.541720e+08\n72.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n1.873453e+09\n\n\n1\nABW\nAruba\n2001\n20.0\n2.3\n11.1\n2000.0\nNaN\n4.2\nNaN\nNaN\nNaN\nNaN\nNaN\n508.0\nNaN\n0.0\n13673.8\n0.0\n4.2\nNaN\nNaN\nNaN\n110.9\n95.3\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n0.9\n91439.0\n49067.0\n1.6\n53.7\n0.1\n46.3\n2.5\n189.7\n0.5\nNaN\nNaN\nNaN\n128.6\n107083798.9\n21.9\n2.018207e+09\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n1.540655e+09\n7.006010e+08\n74.1\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n1.896457e+09\n\n\n2\nABW\nAruba\n2002\n20.0\n2.3\n11.1\n2000.0\nNaN\n4.2\nNaN\nNaN\nNaN\nNaN\nNaN\n511.5\nNaN\n0.0\n12759.1\n0.0\n-0.9\nNaN\nNaN\nNaN\n115.3\n100.3\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n0.7\n92074.0\n49746.0\n1.4\n54.0\n-0.1\n46.0\n2.5\n161.3\n1.0\nNaN\nNaN\nNaN\n93.7\n167910614.5\n26.0\n1.448782e+09\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n1.706137e+09\n7.469060e+08\n76.6\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n1.961844e+09\n\n\n3\nABW\nAruba\n2003\n20.0\n2.3\n11.1\n2000.0\nNaN\n4.2\nNaN\nNaN\nNaN\nNaN\nNaN\n517.4\nNaN\n0.0\n14148.0\n0.0\n1.1\nNaN\nNaN\nNaN\n113.9\n99.4\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n1.1\n93128.0\n50656.0\n1.8\n54.4\n0.3\n45.6\n2.7\n191.7\n1.2\nNaN\nNaN\nNaN\n114.2\n85882681.6\n25.8\n1.766140e+09\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n1.969561e+09\n7.009150e+08\n79.4\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2.044112e+09\n\n\n4\nABW\nAruba\n2004\n20.0\n2.3\n11.1\n2000.0\nNaN\n4.2\nNaN\nNaN\nNaN\nNaN\nNaN\n528.5\n1.3\n0.0\n15276.3\n0.0\n7.3\n1.0\n0.8\nNaN\n116.2\n97.2\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2.1\n95138.0\n52098.0\n2.8\n54.8\n1.3\n45.2\n2.8\n287.0\n1.2\nNaN\nNaN\nNaN\n84.2\n109927374.3\n33.8\n4.687899e+09\n1.2\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2.061564e+09\n7.227750e+08\n81.4\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2.254831e+09\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n5059\nZWE\nZimbabwe\n2019\n162000.0\n45.2\n39.5\n4000000.0\n0.1\n174906.5\nNaN\n1026006.4\n104.3\nNaN\nNaN\n39.5\n-1.3\n9.8\n435782762.1\n2.0\n-6.3\n-0.9\n-1.5\n93.2\n97.5\nNaN\n9.7\n39.8\n50.3\nNaN\n62.4\n70.9\n5772798.0\n39.4\n1.6\n15271368.0\n10352460.0\n1.6\n67.8\n1.6\n32.2\n0.4\n79.6\n2.2\nNaN\n623.5\nNaN\n5.9\n354325147.1\n22.4\n5.266937e+09\n-1.3\nNaN\n1.224936e+10\n4.681985e+08\n1.597240e+09\n16177509.3\n85.1\n2.766927e+10\n-4.066235e+10\n414.7\nNaN\nNaN\nNaN\nNaN\nNaN\n3120.0\nNaN\n2.571741e+10\n\n\n5060\nZWE\nZimbabwe\n2020\n162000.0\n45.1\n39.8\n4000000.0\n0.2\n174445.8\nNaN\n1660964.0\n127.8\nNaN\nNaN\n40.1\n-1.3\n8.8\n487068344.4\n2.3\n-7.8\n-1.1\n-1.4\nNaN\n97.4\nNaN\nNaN\nNaN\nNaN\nNaN\n58.8\n67.8\n5842807.0\n39.5\n1.7\n15526888.0\n10520709.0\n1.6\n67.8\n1.8\n32.2\n0.3\n82.6\n1.7\nNaN\n212.5\nNaN\n4.1\n480586954.8\n17.6\n5.263295e+09\n-1.3\nNaN\n1.274203e+10\n4.876475e+08\n9.846859e+08\n9135529.1\n54.1\n1.066966e+11\n-3.353351e+11\n2725.3\nNaN\nNaN\nNaN\nNaN\n0.5\n3120.0\nNaN\n2.686794e+10\n\n\n5061\nZWE\nZimbabwe\n2021\n162000.0\n45.0\n39.4\n4000000.0\n0.2\n173985.1\nNaN\n2043436.4\n130.0\nNaN\nNaN\n40.8\n-1.3\n8.8\n516326002.5\n1.8\n8.5\n-1.0\n-1.4\nNaN\n96.0\nNaN\nNaN\nNaN\nNaN\nNaN\n53.6\n64.2\n6005429.0\n38.9\n1.7\n15797210.0\n10694237.0\n1.6\n67.7\n1.9\n32.3\n0.3\n118.8\n2.2\nNaN\n212.5\nNaN\n4.3\n662301359.7\n12.8\n6.574804e+09\n-1.3\nNaN\n1.381758e+10\n1.422011e+09\n6.074121e+08\n20165936.9\n61.5\n3.402869e+11\n-3.841839e+11\n5411.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2.724052e+10\n\n\n5062\nZWE\nZimbabwe\n2022\nNaN\n44.9\n39.5\nNaN\n0.2\n173524.4\nNaN\n1887719.5\n123.5\nNaN\nNaN\n41.5\n-1.3\n7.2\nNaN\nNaN\n6.1\n-0.9\n-1.4\n89.8\n95.8\nNaN\nNaN\nNaN\nNaN\nNaN\n52.6\n63.5\n6169164.0\n38.1\n1.7\n16069056.0\n10863485.0\n1.6\n67.6\n2.0\n32.4\n0.3\nNaN\n1.3\nNaN\n212.5\nNaN\n5.8\n630683335.9\n15.0\n7.453497e+09\n-1.3\nNaN\n1.382954e+10\n1.352160e+09\n4.542304e+08\n7842276.0\n68.4\n1.887873e+12\n-2.301768e+12\n11076.6\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n3.278975e+10\n\n\n5063\nZWE\nZimbabwe\n2023\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n-1.2\n4.1\nNaN\nNaN\n5.3\n-0.9\n-1.3\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n6320388.0\nNaN\n1.7\n16340822.0\n11027277.0\n1.5\n67.5\n2.1\n32.5\n0.3\nNaN\n1.2\nNaN\nNaN\nNaN\n5.8\n442297465.1\n17.8\n7.602718e+09\n-1.3\nNaN\n1.421339e+10\n1.363159e+09\n1.161955e+09\n62317585.3\n74.5\n1.666135e+13\n-1.886184e+13\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n3.523137e+10\n\n\n\n\n5064 rows × 68 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n\n    \n  \n\n\nCreate a DataFrame codeDescription that maps World Bank variable codes to their human-readable descriptions, making the data easier to interpret. The DataFrame contains two columns: Variable (the code) and Description (its explanation).\nThe output of this cell is referenced multiple times in subsequent processes to provide clear, descriptive labels for the variables used in the analysis.\n\n\nCode\ncodeDescription = pd.DataFrame(wb.series.info().table(), columns=['Variable', 'Description'])\ncodeDescription\n\n\n\n  \n    \n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\n0\nAG.CON.FERT.PT.ZS\nFertilizer consumption (% of fertilizer produc...\n\n\n1\nAG.CON.FERT.ZS\nFertilizer consumption (kilograms per hectare ...\n\n\n2\nAG.LND.AGRI.K2\nAgricultural land (sq. km)\n\n\n3\nAG.LND.AGRI.ZS\nAgricultural land (% of land area)\n\n\n4\nAG.LND.ARBL.HA\nArable land (hectares)\n\n\n...\n...\n...\n\n\n1492\nVC.IDP.TOCV\nInternally displaced persons, total displaced ...\n\n\n1493\nVC.IHR.PSRC.FE.P5\nIntentional homicides, female (per 100,000 fem...\n\n\n1494\nVC.IHR.PSRC.MA.P5\nIntentional homicides, male (per 100,000 male)\n\n\n1495\nVC.IHR.PSRC.P5\nIntentional homicides (per 100,000 people)\n\n\n1496\n\n1496 elements\n\n\n\n\n1497 rows × 2 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\n\nVisualization of all World Bank Data\nReshape the dataset from wide to long format using pd.melt, where variables are listed under a Variable column, and their corresponding values are placed in a Value column. Essential identifiers like ID, Country, and year are retained, while all other columns are melted. The reshaped data is then grouped by ID, Country, and Variable to calculate the average value of each variable across all years, resulting in two DataFrames: wbData_melted for detailed analysis and wbAverageValue for summarizing variable averages by country.\n\n\nCode\ncolumns_to_keep = [\"ID\", \"Country\", \"year\"]\ndata_columns = wbData.columns.difference(columns_to_keep)\n\n# Use pd.melt to reshape the data\nwbData_melted = pd.melt(\n    wbData,\n    id_vars=columns_to_keep,\n    value_vars=data_columns,\n    var_name=\"Variable\",\n    value_name=\"Value\"\n)\n\n# Calculate the average Value based on year\nwbAverageValue = wbData_melted.groupby(['ID','Country', 'Variable'])['Value'].mean().reset_index()\n\n\nFetch Country Boundaries: A GeoJSON file containing country boundary data is retrieved from the Natural Earth GeoServer. The requests library is used to fetch the data, and it is converted into a GeoDataFrame (world) using geopandas.\n\n\nCode\n# Get country boundaries from Natural Earth GeoServer\nurl = \"https://raw.githubusercontent.com/nvkelso/natural-earth-vector/master/geojson/ne_110m_admin_0_countries.geojson\"\nresponse = requests.get(url, headers={\"Accept\": \"application/json\"})\ngeojson_data = response.json()\nworld = gpd.GeoDataFrame.from_features(geojson_data[\"features\"])\n\n\nThe GeoDataFrame (world) is merged with the previously cleaned World Bank data (wbAverageValue) based on the matching country IDs (WB_A3 from the GeoServer and ID from the cleaned data). This creates a GeoDataFrame (wbDataGeo) that combines spatial and non-spatial data for each country. The merged GeoDataFrame retains only necessary columns: geometry (spatial information for mapping), Country, Variable (World Bank variable), and Value (its average value).\n\n\nCode\n# Merge the GeoDataFrame with Natural Earth GeoServer data\nwbDataGeo = world.merge(wbAverageValue, left_on='WB_A3', right_on='ID', how='inner')\n\n# Keep only the geometry column\nwbDataGeo = wbDataGeo[[\"geometry\", \"Country\", \"Variable\", \"Value\"]]\n\n\nA copy of the merged GeoDataFrame (wbDataGeoCopy) is created and enriched by merging with the codeDescription DataFrame to add human-readable descriptions for each variable. Values are rounded for clearer presentation.\n\n\nCode\n# Create dataframe for visualization\nwbDataGeoCopy = wbDataGeo.copy()\nwbDataGeoVis = pd.merge(wbDataGeoCopy, codeDescription, on='Variable')\nwbDataGeoVis['Value'] = wbDataGeoVis['Value'].round(2)\nwbDataGeoVis.round(1)\n\n\n\n  \n    \n\n\n\n\n\n\ngeometry\nCountry\nVariable\nValue\nDescription\n\n\n\n\n0\nMULTIPOLYGON (((180 -16.06713, 180 -16.55522, ...\nFiji\nAG.CON.FERT.PT.ZS\nNaN\nFertilizer consumption (% of fertilizer produc...\n\n\n1\nMULTIPOLYGON (((180 -16.06713, 180 -16.55522, ...\nFiji\nAG.LND.AGRI.K2\n3290.9\nAgricultural land (sq. km)\n\n\n2\nMULTIPOLYGON (((180 -16.06713, 180 -16.55522, ...\nFiji\nAG.LND.AGRI.ZS\n18.0\nAgricultural land (% of land area)\n\n\n3\nMULTIPOLYGON (((180 -16.06713, 180 -16.55522, ...\nFiji\nAG.LND.ARBL.HA\n79263.6\nArable land (hectares)\n\n\n4\nMULTIPOLYGON (((180 -16.06713, 180 -16.55522, ...\nFiji\nAG.LND.CROP.ZS\n4.2\nPermanent cropland (% of land area)\n\n\n...\n...\n...\n...\n...\n...\n\n\n10655\nPOLYGON ((30.83385 3.50917, 29.9535 4.1737, 29...\nSouth Sudan\nSP.URB.TOTL.IN.ZS\n18.4\nUrban population (% of total population)\n\n\n10656\nPOLYGON ((30.83385 3.50917, 29.9535 4.1737, 29...\nSouth Sudan\nTM.VAL.AGRI.ZS.UN\nNaN\nAgricultural raw materials imports (% of merch...\n\n\n10657\nPOLYGON ((30.83385 3.50917, 29.9535 4.1737, 29...\nSouth Sudan\nTM.VAL.MRCH.XD.WD\nNaN\nImport value index (2015 = 100)\n\n\n10658\nPOLYGON ((30.83385 3.50917, 29.9535 4.1737, 29...\nSouth Sudan\nTX.VAL.AGRI.ZS.UN\nNaN\nAgricultural raw materials exports (% of merch...\n\n\n10659\nPOLYGON ((30.83385 3.50917, 29.9535 4.1737, 29...\nSouth Sudan\nVC.IDP.TOCV\n1280461.5\nInternally displaced persons, total displaced ...\n\n\n\n\n10660 rows × 5 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n\n    \n  \n\n\nCreate an interactive geospatial map using hvplot to visualize World Bank data across countries. The map displays variable values (Value) with color gradients (cmap=‘plasma’) on a dark background (tiles=‘CartoDark’) and allows users to switch between variables using a dropdown menu (groupby=‘Description’). Hover functionality reveals country names and values, and the map is styled with a minimal dark theme for clarity.\n\n\nCode\n# Boundary\nx_rangemap = (-180, 180)\ny_rangemap = (-90, 90)\n\n# Create map\nimg = wbDataGeoVis.hvplot(\n    geo=True,\n    dynamic=False,\n    tiles='CartoDark',\n    frame_width=400,\n    frame_height=400,\n    c='Value',\n    groupby='Description',\n    cmap='plasma',\n    hover_cols=['Country', 'Value'],\n    xlim=x_rangemap,\n    ylim=y_rangemap\n)\n\nhv.renderer('bokeh').theme = 'dark_minimal'\nimg\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\nVisualization of Missing Data:\nGenerate a heatmap to visualize missing values in the dataset, sorted by columns and countries. It calculates the number of NaN values per column and country, reorders the data accordingly, and creates a binary DataFrame (NaN vs. non-NaN) for the heatmap. The plot uses color coding (blue for NaN and green for valid data) to highlight patterns of missing data, helping in understanding the extent of missing data and deciding on the cleaning strategy.\n\n\nCode\n# Recalculate the number of NaN values per column and per country\nhmColumnSort = wbData.isna().sum().sort_values(ascending=False)\nhmCountrySort = wbData.set_index(['ID', 'Country']).isna().sum(axis=1).sort_values(ascending=False)\n\n# Reorder the DataFrame based on sorted NaN counts\nhmSort = wbData[hmColumnSort.index]\n\n# Reorder the countries based on their NaN counts\nhmSort = hmSort.set_index(['ID', 'Country']).loc[hmCountrySort.index]\n\n# Create a DataFrame indicating NaN values for the heatmap\nhmBothSort = hmSort.isna()\n\n# Plotting the heatmap\nplt.figure(figsize=(20, 10))\nsns.heatmap(\n    hmBothSort.T,\n    cmap=['#82C574', '#3F597C'],\n    cbar=True,\n    cbar_kws={'label': 'Blue = NaN, Green = Not NaN'}\n)\n\nplt.title('Heatmap of Missing Values (Sorted by Columns and Countries)', fontsize=16)\nplt.xlabel('Country (ID)', fontsize=12)\nplt.ylabel('Columns (Variables)', fontsize=12)\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "analysis/Final_project.html#missing-data",
    "href": "analysis/Final_project.html#missing-data",
    "title": "Analysis",
    "section": "Missing data",
    "text": "Missing data\nMissing values are handled using a threshold to remove columns or rows with excessive missing data.\nMissing values (NaN) in each column are counted and sorted in descending order to identify variables with the most missing data.\n\n\nCode\n# Display NaN data each column\nnan_counts = wbData.isna().sum().sort_values(ascending=False)\n\n\nColumns where missing values exceed half the total number of rows are removed (columns_to_drop), as they lack sufficient data for meaningful analysis.\n\n\nCode\n# Drop columns NaN\nhalfWbDataNan = len(wbData) / 2\ncolumns_to_drop = nan_counts[nan_counts &gt;= halfWbDataNan].index\nwbDataDropColumns = wbData.drop(columns=columns_to_drop)\nwbDataDropColumns.round(1)\n\n\n\n  \n    \n\n\n\n\n\n\nID\nCountry\nyear\nAG.LND.AGRI.K2\nAG.LND.FRST.ZS\nAG.LND.AGRI.ZS\nAG.LND.ARBL.HA\nAG.LND.CROP.ZS\nAG.LND.FRST.K2\nAG.PRD.CREL.MT\nAG.PRD.CROP.XD\nEN.POP.DNST\nGE.EST\nNV.AGR.TOTL.ZS\nNY.ADJ.DFOR.CD\nNY.GDP.FRST.RT.ZS\nNY.GDP.MKTP.KD.ZG\nPV.EST\nRQ.EST\nSE.PRM.ENRR\nSE.SEC.ENRR\nSL.AGR.EMPL.ZS\nSL.EMP.SELF.ZS\nSL.TLF.TOTL.IN\nSN.ITK.DEFC.ZS\nSP.POP.GROW\nSP.POP.TOTL\nSP.RUR.TOTL\nSP.RUR.TOTL.ZG\nSP.RUR.TOTL.ZS\nSP.URB.GROW\nSP.URB.TOTL.IN.ZS\nTM.VAL.AGRI.ZS.UN\nTM.VAL.MRCH.XD.WD\nTX.VAL.AGRI.ZS.UN\nBG.GSR.NFSV.GD.ZS\nBM.GSR.FCTY.CD\nBM.GSR.TRVL.ZS\nBX.GSR.GNFS.CD\nCC.EST\nDT.DOD.DECT.CD\nDT.DOD.DIMF.CD\nDT.TDS.DECT.CD\nDT.TDS.MLAT.CD\nFM.AST.DOMS.CN\nFM.AST.NFRG.CN\nFP.CPI.TOTL\nGC.TAX.GSRV.CN\nGC.XPN.TRFT.CN\nNY.GDP.MKTP.CD\n\n\n\n\n0\nABW\nAruba\n2000\n20.0\n2.3\n11.1\n2000.0\nNaN\n4.2\nNaN\nNaN\n503.3\nNaN\n0.0\n13173.8\n0.0\n7.6\nNaN\nNaN\n108.3\n93.8\nNaN\nNaN\nNaN\nNaN\n1.0\n90588.0\n48268.0\n1.8\n53.3\n0.2\n46.7\n2.9\n206.5\n0.7\n119.0\n77016759.8\n22.6\n1.815620e+09\nNaN\nNaN\nNaN\nNaN\nNaN\n1.478961e+09\n5.541720e+08\n72.0\nNaN\nNaN\n1.873453e+09\n\n\n1\nABW\nAruba\n2001\n20.0\n2.3\n11.1\n2000.0\nNaN\n4.2\nNaN\nNaN\n508.0\nNaN\n0.0\n13673.8\n0.0\n4.2\nNaN\nNaN\n110.9\n95.3\nNaN\nNaN\nNaN\nNaN\n0.9\n91439.0\n49067.0\n1.6\n53.7\n0.1\n46.3\n2.5\n189.7\n0.5\n128.6\n107083798.9\n21.9\n2.018207e+09\nNaN\nNaN\nNaN\nNaN\nNaN\n1.540655e+09\n7.006010e+08\n74.1\nNaN\nNaN\n1.896457e+09\n\n\n2\nABW\nAruba\n2002\n20.0\n2.3\n11.1\n2000.0\nNaN\n4.2\nNaN\nNaN\n511.5\nNaN\n0.0\n12759.1\n0.0\n-0.9\nNaN\nNaN\n115.3\n100.3\nNaN\nNaN\nNaN\nNaN\n0.7\n92074.0\n49746.0\n1.4\n54.0\n-0.1\n46.0\n2.5\n161.3\n1.0\n93.7\n167910614.5\n26.0\n1.448782e+09\nNaN\nNaN\nNaN\nNaN\nNaN\n1.706137e+09\n7.469060e+08\n76.6\nNaN\nNaN\n1.961844e+09\n\n\n3\nABW\nAruba\n2003\n20.0\n2.3\n11.1\n2000.0\nNaN\n4.2\nNaN\nNaN\n517.4\nNaN\n0.0\n14148.0\n0.0\n1.1\nNaN\nNaN\n113.9\n99.4\nNaN\nNaN\nNaN\nNaN\n1.1\n93128.0\n50656.0\n1.8\n54.4\n0.3\n45.6\n2.7\n191.7\n1.2\n114.2\n85882681.6\n25.8\n1.766140e+09\nNaN\nNaN\nNaN\nNaN\nNaN\n1.969561e+09\n7.009150e+08\n79.4\nNaN\nNaN\n2.044112e+09\n\n\n4\nABW\nAruba\n2004\n20.0\n2.3\n11.1\n2000.0\nNaN\n4.2\nNaN\nNaN\n528.5\n1.3\n0.0\n15276.3\n0.0\n7.3\n1.0\n0.8\n116.2\n97.2\nNaN\nNaN\nNaN\nNaN\n2.1\n95138.0\n52098.0\n2.8\n54.8\n1.3\n45.2\n2.8\n287.0\n1.2\n84.2\n109927374.3\n33.8\n4.687899e+09\n1.2\nNaN\nNaN\nNaN\nNaN\n2.061564e+09\n7.227750e+08\n81.4\nNaN\nNaN\n2.254831e+09\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n5059\nZWE\nZimbabwe\n2019\n162000.0\n45.2\n39.5\n4000000.0\n0.1\n174906.5\n1026006.4\n104.3\n39.5\n-1.3\n9.8\n435782762.1\n2.0\n-6.3\n-0.9\n-1.5\n97.5\nNaN\n62.4\n70.9\n5772798.0\n39.4\n1.6\n15271368.0\n10352460.0\n1.6\n67.8\n1.6\n32.2\n0.4\n79.6\n2.2\n5.9\n354325147.1\n22.4\n5.266937e+09\n-1.3\n1.224936e+10\n4.681985e+08\n1.597240e+09\n16177509.3\n2.766927e+10\n-4.066235e+10\n414.7\nNaN\nNaN\n2.571741e+10\n\n\n5060\nZWE\nZimbabwe\n2020\n162000.0\n45.1\n39.8\n4000000.0\n0.2\n174445.8\n1660964.0\n127.8\n40.1\n-1.3\n8.8\n487068344.4\n2.3\n-7.8\n-1.1\n-1.4\n97.4\nNaN\n58.8\n67.8\n5842807.0\n39.5\n1.7\n15526888.0\n10520709.0\n1.6\n67.8\n1.8\n32.2\n0.3\n82.6\n1.7\n4.1\n480586954.8\n17.6\n5.263295e+09\n-1.3\n1.274203e+10\n4.876475e+08\n9.846859e+08\n9135529.1\n1.066966e+11\n-3.353351e+11\n2725.3\nNaN\nNaN\n2.686794e+10\n\n\n5061\nZWE\nZimbabwe\n2021\n162000.0\n45.0\n39.4\n4000000.0\n0.2\n173985.1\n2043436.4\n130.0\n40.8\n-1.3\n8.8\n516326002.5\n1.8\n8.5\n-1.0\n-1.4\n96.0\nNaN\n53.6\n64.2\n6005429.0\n38.9\n1.7\n15797210.0\n10694237.0\n1.6\n67.7\n1.9\n32.3\n0.3\n118.8\n2.2\n4.3\n662301359.7\n12.8\n6.574804e+09\n-1.3\n1.381758e+10\n1.422011e+09\n6.074121e+08\n20165936.9\n3.402869e+11\n-3.841839e+11\n5411.0\nNaN\nNaN\n2.724052e+10\n\n\n5062\nZWE\nZimbabwe\n2022\nNaN\n44.9\n39.5\nNaN\n0.2\n173524.4\n1887719.5\n123.5\n41.5\n-1.3\n7.2\nNaN\nNaN\n6.1\n-0.9\n-1.4\n95.8\nNaN\n52.6\n63.5\n6169164.0\n38.1\n1.7\n16069056.0\n10863485.0\n1.6\n67.6\n2.0\n32.4\n0.3\nNaN\n1.3\n5.8\n630683335.9\n15.0\n7.453497e+09\n-1.3\n1.382954e+10\n1.352160e+09\n4.542304e+08\n7842276.0\n1.887873e+12\n-2.301768e+12\n11076.6\nNaN\nNaN\n3.278975e+10\n\n\n5063\nZWE\nZimbabwe\n2023\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n-1.2\n4.1\nNaN\nNaN\n5.3\n-0.9\n-1.3\nNaN\nNaN\nNaN\nNaN\n6320388.0\nNaN\n1.7\n16340822.0\n11027277.0\n1.5\n67.5\n2.1\n32.5\n0.3\nNaN\n1.2\n5.8\n442297465.1\n17.8\n7.602718e+09\n-1.3\n1.421339e+10\n1.363159e+09\n1.161955e+09\n62317585.3\n1.666135e+13\n-1.886184e+13\nNaN\nNaN\nNaN\n3.523137e+10\n\n\n\n\n5064 rows × 50 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n\n    \n  \n\n\nRows with any NaN values are dropped to retain only complete records for further analysis (rows_without_nan).\n\n\nCode\n# Select rows with no NaN values\nrows_without_nan = wbDataDropColumns.dropna(how='any')\n\n# Count rows for each country\ncountry_counts = rows_without_nan['Country'].value_counts()\n\n\nCounts the number of valid rows per country and filters countries with at least 7 valid entries, ensuring sufficient data coverage for each country.\n\n\nCode\n# Filter countries with at least 7 rows\nfiltered_countries = country_counts[country_counts &gt;= 7].index\n\n# Retain rows only for countries with at least 10 entries\npreProceedData = rows_without_nan[rows_without_nan['Country'].isin(filtered_countries)]\n\n\n\n\nCode\npreProceedData['Country'].value_counts().sort_values(ascending=True)\nprint(\"Total selected countries: \", len(preProceedData['Country'].value_counts()))\n\n\nTotal selected countries:  51\n\n\n\nVisualization of filtered countries\nCreate a geospatial visualization using folium to map filtered countries. The process starts by setting the coordinate reference system (CRS) of the GeoDataFrame (world) to WGS 84 for compatibility, followed by merging it with the cleaned dataset (preProceedData) based on country IDs. The merged data is then converted to GeoJSON format for mapping. A folium.Map is created with a dark background, and a GeoJson layer is added to highlight the filtered countries with a white fill color. The map includes zoom controls and interactive tooltips displaying country names for better exploration.\n\n\nCode\n# Set the CRS for the 'world' GeoDataFrame before merging\nworld = world.set_crs(\"epsg:4326\")  # Assuming the GeoJSON is in WGS 84\n\n# Merge the GeoDataFrame with Natural Earth GeoServer data\ngdf = world.merge(preProceedData, left_on='WB_A3', right_on='ID', how='inner')\n\n# Convert the GeoDataFrame to GeoJSON format\ngdf_json = gdf.to_crs(\"epsg:4326\").to_json()\n\n# Create a folium map\nm = folium.Map(\n    location=[30, 0],\n    zoom_start=2,\n    tiles='CartoDB dark_matter',\n    max_bounds=True,\n    max_zoom=10,\n    min_zoom=2\n)\n\n# Add a layer for filtered countries with white fill color\nfolium.GeoJson(\n    data=gdf_json,\n    style_function=lambda x: {\n        'fillColor': 'white',\n        'color': '#3F597C',\n        'weight': 0.5,\n        'fillOpacity': 0.7\n    },\n    tooltip=folium.GeoJsonTooltip(fields=['Country'], aliases=['Country:'])\n).add_to(m)\n\n# Display map\nm\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook"
  },
  {
    "objectID": "analysis/Final_project.html#dependent-variable",
    "href": "analysis/Final_project.html#dependent-variable",
    "title": "Analysis",
    "section": "Dependent variable",
    "text": "Dependent variable\nThe dependent variable, “Deforestation,” is computed as the year-on-year difference in forest area for each country and prepare it for further analysis and visualization.\nThe dataset is sorted by Country and year to ensure chronological consistency. The Deforestation variable is then calculated as the year-on-year difference in forest area (AG.LND.FRST.K2) for each country using the diff function, capturing annual changes in forest cover. Missing values from the calculation are handled by dropping incomplete rows. A copy of the processed data is created for visualization, and the regions are mapped to their full names for clarity. This dependent variable is essential for modeling deforestation trends and understanding the dynamics behind forest loss, while the cleaned and enriched data supports detailed visual and statistical analyses.\n\n\nCode\n# Reset index\npreProceedData2 = preProceedData.reset_index()\n\n# Ensure the data is sorted correctly\npreProceedData2 = preProceedData2.sort_values(by=['Country', 'year'])\n\n# Calculate the deforestation for each country by subtracting the forest area of the previous year\npreProceedData2['Deforestation'] = preProceedData2.groupby('Country')['AG.LND.FRST.K2'].diff()\n\n# For visualization\nforVis = preProceedData2.copy()\nforVis['Deforestation'] = forVis['Deforestation'].fillna(0)\n\n# Select rows with no NaN values\npreProceedData2 = preProceedData2.dropna(how='any')\n\n\n\nVisualization of deforestation\nEnrich the dataset for visualization by adding region information. It merges the data (forVis) with a filtered list of countries and their regions (allCountryFilt) based on country names. A new column, region_full, is added by mapping region abbreviations to their full names (e.g., “EAS” to “East Asia and Pacific”) using a predefined dictionary.\n\n\nCode\n#Additional region data for visualization\nallCountryFilt = allCountry[['name', 'region']]\n\nforVis2 = pd.merge(forVis, allCountryFilt, left_on=['Country'], right_on=['name'], how='inner')\n\n# Add a column to explain region abbreviations\nregion_mapping = {\n    \"EAS\": \"East Asia and Pacific\",\n    \"ECS\": \"Europe and Central Asia\",\n    \"LCN\": \"Latin America and Caribbean\",\n    \"MEA\": \"Middle East and North Africa\",\n    \"SAS\": \"South Asia\",\n    \"SSF\": \"Sub-Saharan Africa\"\n}\nforVis2['region_full'] = forVis2['region'].map(region_mapping)\n\n\nCreates an interactive stacked bar chart using Altair to visualize reported deforestation trends by region over the years. Custom colors are defined for each region, and a brush selection feature allows users to click on specific countries to highlight their data. The chart groups data by region_full and represents the sum of deforestation for each year, with a tooltip displaying details like Country, year, and region.\n\n\nCode\n#Define custom colors\ncustomColor = ['#7DC1DD','#EB9E42','#DF7068','#82C574','#82888D','#3F597C']\n\n#Create a point selection for the chart\nbrush = alt.selection_point(fields=['Country'], on='click')\n\n# Altair plot as a stacked bar chart\ndeforestation_chart = alt.Chart(forVis2).mark_bar(stroke='white', strokeWidth=0.5).encode(\n    x=alt.X('year:O', title='Year'),\n    y=alt.Y('sum(Deforestation):Q', title='Change in Forest Area, sq. km (Negative = forest loss)'),\n    color=alt.condition(\n        brush,\n        alt.Color(\"region_full:N\", scale=alt.Scale(range=customColor), legend=alt.Legend(title=\"Region\", orient=\"bottom-left\")),\n        alt.value('lightgray')\n    ),\n    tooltip=['Country', 'year', 'Deforestation', 'region', 'region_full']\n).add_params(\n    brush\n).properties(\n    title='Reported Deforestation',\n    width=800,\n    height=400\n)\n\n# Customize the legend position\nfinal_chart = deforestation_chart.configure_legend(\n    orient='bottom-left',\n    titleFontSize=12,\n    labelFontSize=10,\n    fillColor='white'\n)\n\n# Show the plot\nfinal_chart"
  },
  {
    "objectID": "analysis/Final_project.html#independent-variables",
    "href": "analysis/Final_project.html#independent-variables",
    "title": "Analysis",
    "section": "Independent variables",
    "text": "Independent variables\nA correlation matrix is generated to identify variables that are highly correlated which will be excluded to reduce redundancy and improve model interpretability. This code calculates the correlation matrix for numerical variables in the dataset to identify relationships between them.\nA mask is created to cover the upper triangle of the matrix, leaving only the lower triangle visible for analysis (for distribution graph only)\n\n\nCode\n# Compute the correlation matrix\ncorr = preProceedData2.select_dtypes(include=['number']).corr()\n\n# Create a mask for the upper triangle\nmask = np.triu(np.ones_like(corr, dtype=bool))\n\n# Extract the values from the lower triangle of the correlation matrix\nlower_triangle_values = corr.where(~mask).stack().values\n\n\n\nVisualization of correlation matrix\nVisualize the correlation matrix and its distribution using side-by-side plots. A custom color gradient is defined for the heatmap to highlight correlations, which is plotted in the first subplot to show relationships between numerical variables. The second subplot displays a histogram of the lower triangle correlation values, with a density curve (kde) overlaid to illustrate the distribution of correlation strengths. Together, these plots help identify patterns and potential multicollinearity in the dataset.\n\n\nCode\n# Define a custom color gradient\ncustom_cmap = LinearSegmentedColormap.from_list(\n    \"custom_gradient\",\n    [\"#82C574\", \"#FFFFFF\", \"#DF7068\"]\n)\n\n# Create side-by-side plots\nfig, axes = plt.subplots(1, 2, figsize=(20, 8))\n\n# Plot the heatmap on the first subplot\nsns.heatmap(\n    preProceedData2.select_dtypes(include=['number']).corr(),\n    cmap=custom_cmap,\n    annot=False,\n    vmin=-1,\n    vmax=1,\n    #mask=mask,\n    ax=axes[0]\n)\naxes[0].set_title('Correlation Matrix Heatmap', fontsize=16)\n\n# Plot the distribution on the second subplot\nsns.histplot(\n    lower_triangle_values,\n    bins=30,\n    kde=True,\n    color='#7DC1DD',\n    ax=axes[1]\n)\naxes[1].set_title('Distribution of Lower Triangle Correlation Values', fontsize=16)\naxes[1].set_xlabel('Correlation Value', fontsize=12)\naxes[1].set_ylabel('Frequency', fontsize=12)\naxes[1].grid(True)\n\n# Adjust layout and show the plot\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nIdentify pairs of variables with high correlations (≥ 0.9 or ≤ -0.9), which indicate potential multicollinearity. Using the masked lower triangle of the correlation matrix, it iterates through variable pairs to extract those meeting the threshold. These pairs, along with their correlation values, are stored in a list and converted into a DataFrame (high_correl) for better visualization and analysis. This helps in pinpointing strongly correlated variables that may need to be excluded or handled in modeling.\n\n\nCode\n# Identify correlations &gt;= 0.9 or &lt;= -0.9\nhigh_corr = corr[(corr &gt;= 0.9) | (corr &lt;= -0.9)]\n\n# Get the column names of high_corr\nhigh_corr_columns = high_corr.index\n\n# Apply the mask to keep only the lower triangle\ncorr_masked = corr.where(~mask)\n\n# Identify correlations &gt;= 0.9 or &lt;= -0.9 in the lower triangle\nhigh_corr_pairs = []\nfor i in corr_masked.index:\n    for j in corr_masked.columns:\n        if not pd.isna(corr_masked.loc[i, j]) and ((corr_masked.loc[i, j] &gt;= 0.9) or (corr_masked.loc[i, j] &lt;= -0.9)):\n            high_corr_pairs.append((i, j, corr_masked.loc[i, j]))\n\n# Convert to a DataFrame for better visualization\nhigh_correl = pd.DataFrame(high_corr_pairs, columns=['Variable 1', 'Variable 2', 'Correlation'])\n\n\nEnriches the highly correlated variable pairs (high_correl) by merging them with the codeDescription DataFrame to replace variable codes with their human-readable descriptions. Each variable pair is processed separately, renaming and organizing columns for clarity. The final DataFrame, high_corr_df, presents the pairs with their descriptive names and correlation values.\n\n\nCode\n# Merge the two dataframes for variable 1\nhigh_corr_var1 = pd.merge(\n    high_correl,\n    codeDescription,\n    left_on='Variable 1',\n    right_on='Variable',\n    how='left'\n)\n\nhigh_corr_var1 = high_corr_var1.drop(columns=['Variable','Variable 1'])\n\n# Rename a column in the dataframe\nhigh_corr_var1.rename(columns={'Description': 'Variable 1'}, inplace=True)\n\n# Merge the two dataframes for variable 2\nhigh_corr_df = pd.merge(\n    high_corr_var1,\n    codeDescription,\n    left_on='Variable 2',\n    right_on='Variable',\n    how='left'\n)\n\nhigh_corr_df = high_corr_df.drop(columns=['Variable','Variable 2'])\n\n# Rename a column in the dataframe\nhigh_corr_df.rename(columns={'Description': 'Variable 2'}, inplace=True)\n\nhigh_corr_df = high_corr_df[['Variable 1', 'Variable 2', 'Correlation']]\n\n# Display the result\nhigh_corr_df.round(2)\n\n\n\n  \n    \n\n\n\n\n\n\nVariable 1\nVariable 2\nCorrelation\n\n\n\n\n0\nCereal production (metric tons)\nArable land (hectares)\n0.97\n\n\n1\nSelf-employed, total (% of total employment) (...\nEmployment in agriculture (% of total employme...\n0.90\n\n\n2\nLabor force, total\nArable land (hectares)\n0.94\n\n\n3\nLabor force, total\nCereal production (metric tons)\n0.96\n\n\n4\nPopulation, total\nArable land (hectares)\n0.94\n\n\n5\nPopulation, total\nCereal production (metric tons)\n0.95\n\n\n6\nPopulation, total\nLabor force, total\n1.00\n\n\n7\nRural population\nArable land (hectares)\n0.91\n\n\n8\nRural population\nCereal production (metric tons)\n0.90\n\n\n9\nRural population\nLabor force, total\n0.97\n\n\n10\nRural population\nPopulation, total\n0.99\n\n\n11\nUrban population growth (annual %)\nPopulation growth (annual %)\n0.91\n\n\n12\nUrban population (% of total population)\nRural population (% of total population)\n-1.00\n\n\n13\nDebt service on external debt, total (TDS, cur...\nExternal debt stocks, total (DOD, current US$)\n0.93\n\n\n14\nNet foreign assets (current LCU)\nNet domestic credit (current LCU)\n0.99\n\n\n15\nTaxes on goods and services (current LCU)\nNet domestic credit (current LCU)\n0.99\n\n\n16\nTaxes on goods and services (current LCU)\nNet foreign assets (current LCU)\n0.99\n\n\n17\nSubsidies and other transfers (current LCU)\nNet domestic credit (current LCU)\n0.98\n\n\n18\nSubsidies and other transfers (current LCU)\nNet foreign assets (current LCU)\n0.99\n\n\n19\nSubsidies and other transfers (current LCU)\nTaxes on goods and services (current LCU)\n0.99\n\n\n20\nGDP (current US$)\nExternal debt stocks, total (DOD, current US$)\n0.93\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n\n    \n  \n\n\nAggregate the variables from highly correlated pairs to identify which variables are most frequently involved in strong correlations. It combines Variable 1 and Variable 2 into a single series, counts their occurrences, and converts the result into a DataFrame (variable_counts_df) for better visualization. This highlights variables that are repeatedly involved in multicollinearity, helping to prioritize them for further investigation or potential exclusion from the analysis.\n\n\nCode\n# Combine Variable 1 and Variable 2 into a single series\nall_variables = pd.concat([high_corr_df['Variable 1'], high_corr_df['Variable 2']])\n\n# Count the occurrences of each variable\nvariable_counts = all_variables.value_counts()\n\n# Convert to a DataFrame for better visualization\nvariable_counts_df = variable_counts.reset_index()\nvariable_counts_df.columns = ['Variable', 'Count']\n\n# Display the result\nvariable_counts_df\n\n\n\n  \n    \n\n\n\n\n\n\nVariable\nCount\n\n\n\n\n0\nCereal production (metric tons)\n4\n\n\n1\nLabor force, total\n4\n\n\n2\nPopulation, total\n4\n\n\n3\nRural population\n4\n\n\n4\nArable land (hectares)\n4\n\n\n5\nNet foreign assets (current LCU)\n3\n\n\n6\nSubsidies and other transfers (current LCU)\n3\n\n\n7\nTaxes on goods and services (current LCU)\n3\n\n\n8\nNet domestic credit (current LCU)\n3\n\n\n9\nExternal debt stocks, total (DOD, current US$)\n2\n\n\n10\nDebt service on external debt, total (TDS, cur...\n1\n\n\n11\nSelf-employed, total (% of total employment) (...\n1\n\n\n12\nUrban population (% of total population)\n1\n\n\n13\nGDP (current US$)\n1\n\n\n14\nUrban population growth (annual %)\n1\n\n\n15\nEmployment in agriculture (% of total employme...\n1\n\n\n16\nPopulation growth (annual %)\n1\n\n\n17\nRural population (% of total population)\n1\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\nTo address multicollinearity issues in the dataset, specific variables have been selected for exclusion based on their strong correlations with others. These variables, listed in corrExclude, are removed to reduce redundancy and improve the reliability and interpretability of subsequent analyses. This decision ensures that the remaining variables provide unique and meaningful contributions to the models and analyses.\n\n\nCode\n# Decide to exclude some variables in response of collinearity issue\ncorrExclude = ['AG.PRD.CREL.MT',\n'DT.DOD.DECT.CD',\n'FM.AST.NFRG.CN',\n'GC.TAX.GSRV.CN',\n'SL.EMP.SELF.ZS',\n'BX.GSR.GNFS.CD',\n'DT.DOD.DECT.CD',\n'FM.AST.DOMS.CN',\n'FM.AST.NFRG.CN',\n'GC.TAX.GSRV.CN',\n'SP.RUR.TOTL.ZS',\n]\n\n\nEnriches the dataset by adding additional categorical information. The filtered allCountry DataFrame, containing region and incomeLevel data, is merged with the cleaned data (preProceedData2) based on country names.\n\n\nCode\n#Additional categorical data\n#Select only the required columns\nallCountryFiltered = allCountry[['name', 'region', 'incomeLevel']]\n\nadditionalMerged = pd.merge(preProceedData2, allCountryFiltered, left_on=['Country'], right_on=['name'], how='inner')\n\n\nIdentify variables to exclude from the dataset by combining two exclusion lists: corrExclude, which contains variables removed due to multicollinearity, and specific_excludes, which includes columns not relevant for analysis (e.g., identifiers like ID and name).\n\n\nCode\n# Columns to exclude from preProceedData2\nspecific_excludes = ['index', 'ID', 'AG.LND.FRST.K2','name']\n\n# Combine corrExclude with specific columns to exclude\nvariableXExclude = list(set(corrExclude + specific_excludes))\n\n\nCreates a cleaned dataset, ensuring that redundant, irrelevant, or highly correlated variables are excluded, leaving a refined dataset ready for further analysis or modeling.\n\n\nCode\ndataForRf = additionalMerged[[col for col in additionalMerged.columns if col not in variableXExclude]]\ndataForRf.round(1)\n\n\n\n  \n    \n\n\n\n\n\n\nCountry\nyear\nAG.LND.AGRI.K2\nAG.LND.FRST.ZS\nAG.LND.AGRI.ZS\nAG.LND.ARBL.HA\nAG.LND.CROP.ZS\nAG.PRD.CROP.XD\nEN.POP.DNST\nGE.EST\nNV.AGR.TOTL.ZS\nNY.ADJ.DFOR.CD\nNY.GDP.FRST.RT.ZS\nNY.GDP.MKTP.KD.ZG\nPV.EST\nRQ.EST\nSE.PRM.ENRR\nSE.SEC.ENRR\nSL.AGR.EMPL.ZS\nSL.TLF.TOTL.IN\nSN.ITK.DEFC.ZS\nSP.POP.GROW\nSP.POP.TOTL\nSP.RUR.TOTL\nSP.RUR.TOTL.ZG\nSP.URB.GROW\nSP.URB.TOTL.IN.ZS\nTM.VAL.AGRI.ZS.UN\nTM.VAL.MRCH.XD.WD\nTX.VAL.AGRI.ZS.UN\nBG.GSR.NFSV.GD.ZS\nBM.GSR.FCTY.CD\nBM.GSR.TRVL.ZS\nCC.EST\nDT.DOD.DIMF.CD\nDT.TDS.DECT.CD\nDT.TDS.MLAT.CD\nFP.CPI.TOTL\nGC.XPN.TRFT.CN\nNY.GDP.MKTP.CD\nDeforestation\nregion\nincomeLevel\n\n\n\n\n0\nAlbania\n2003\n11210.0\n28.2\n40.9\n578000.0\n4.4\n54.9\n110.9\n-0.6\n22.0\n3535170.7\n0.1\n5.5\n-0.3\n-0.5\n107.6\n77.8\n48.0\n1290479.0\n7.4\n-0.4\n3039616.0\n1684768.0\n-2.3\n2.1\n44.6\n1.0\n43.3\n5.1\n27.6\n2.436447e+07\n60.9\n-0.9\n1.594152e+08\n5.727977e+07\n2.021326e+07\n82.8\n5.728388e+10\n5.611496e+09\n12.8\nECS\nUMC\n\n\n1\nAlbania\n2004\n11220.0\n28.3\n40.9\n578000.0\n4.4\n58.5\n110.5\n-0.4\n20.5\n3879499.9\n0.1\n5.5\n-0.4\n-0.2\n104.1\n79.0\n47.6\n1275704.0\n8.6\n-0.4\n3026939.0\n1645111.0\n-2.4\n2.0\n45.7\n1.1\n53.7\n4.5\n30.0\n2.832284e+07\n60.8\n-0.7\n1.690999e+08\n7.602167e+07\n2.783090e+07\n84.7\n7.013519e+10\n7.184686e+09\n12.8\nECS\nUMC\n\n\n2\nAlbania\n2011\n12010.0\n28.6\n43.8\n622000.0\n2.7\n87.4\n106.0\n-0.2\n18.2\n27102197.8\n0.2\n2.5\n-0.3\n0.3\n101.6\n95.5\n45.4\n1376967.0\n4.8\n-0.3\n2905195.0\n1358266.0\n-2.6\n1.8\n53.2\n1.0\n125.4\n2.6\n39.3\n2.986859e+08\n69.6\n-0.7\n1.172413e+08\n4.825108e+08\n8.207203e+07\n103.4\n1.358977e+11\n1.289076e+10\n90.9\nECS\nUMC\n\n\n3\nAlbania\n2012\n12013.0\n28.6\n43.8\n619100.0\n2.8\n93.9\n105.9\n-0.3\n18.8\n22486375.5\n0.2\n1.4\n-0.1\n0.2\n102.1\n97.6\n46.0\n1317523.0\n4.5\n-0.2\n2900401.0\n1324613.0\n-2.5\n1.8\n54.3\n0.9\n113.5\n2.5\n34.9\n3.329938e+08\n68.6\n-0.8\n1.070361e+08\n5.425489e+08\n8.957130e+07\n105.5\n1.399201e+11\n1.231983e+10\n14.2\nECS\nUMC\n\n\n4\nAlbania\n2013\n11873.0\n28.7\n43.3\n617100.0\n2.9\n93.7\n105.7\n-0.3\n19.6\n21100579.4\n0.2\n1.0\n0.1\n0.3\n101.5\n102.9\n44.2\n1217209.0\n4.4\n-0.2\n2895092.0\n1291587.0\n-2.5\n1.7\n55.4\n1.0\n113.9\n2.3\n33.4\n1.504106e+08\n74.7\n-0.8\n9.675547e+07\n5.504619e+08\n1.013739e+08\n107.6\n1.517697e+11\n1.277622e+10\n14.2\nECS\nUMC\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n604\nUkraine\n2017\n414890.0\n16.7\n71.6\n32773000.0\n1.5\n100.8\n78.4\n-0.5\n10.2\n0.0\n0.4\n2.4\n-1.9\n-0.3\n88.2\n86.8\n15.4\n21646826.0\n2.6\n-0.4\n45436041.0\n13973400.0\n-0.7\n-0.3\n69.2\n1.2\n132.2\n1.7\n24.6\n7.691000e+09\n53.4\n-0.8\n1.400143e+10\n1.322454e+10\n2.139854e+09\n235.3\n6.123422e+11\n1.120905e+11\n70.0\nECS\nUMC\n\n\n605\nUkraine\n2018\n413290.0\n16.7\n71.3\n32889000.0\n1.5\n111.1\n78.0\n-0.5\n10.1\n0.0\n0.4\n3.5\n-1.9\n-0.3\n88.6\n85.8\n15.3\n21532913.0\n3.0\n-0.5\n45208907.0\n13855626.0\n-0.8\n-0.3\n69.4\n1.1\n152.4\n2.0\n23.2\n1.058100e+10\n54.5\n-0.9\n1.299723e+10\n1.476636e+10\n2.223670e+09\n261.1\n7.081612e+11\n1.308911e+11\n70.0\nECS\nUMC\n\n\n606\nUkraine\n2019\n413110.0\n16.7\n71.3\n32924000.0\n1.5\n112.8\n77.6\n-0.3\n9.0\n0.0\n0.3\n3.2\n-1.4\n-0.2\n90.7\n84.5\n15.2\n21427949.0\n3.7\n-0.6\n44957458.0\n13724163.0\n-1.0\n-0.4\n69.5\n1.0\n162.1\n1.7\n21.6\n1.137100e+10\n54.2\n-0.8\n1.132839e+10\n1.395323e+10\n1.250666e+09\n281.7\n7.612929e+11\n1.538830e+11\n60.0\nECS\nUMC\n\n\n607\nUkraine\n2020\n413110.0\n16.7\n71.3\n32924000.0\n1.5\n100.9\n77.1\n-0.4\n9.3\n0.0\n0.3\n-3.8\n-1.2\n-0.3\n91.1\n84.4\n15.3\n20852330.0\n4.3\n-0.6\n44680014.0\n13579150.0\n-1.1\n-0.4\n69.6\n1.1\n144.8\n1.7\n17.1\n8.629000e+09\n42.0\n-0.8\n1.282442e+10\n1.739990e+10\n1.304253e+09\n289.4\n8.467340e+11\n1.566177e+11\n60.0\nECS\nUMC\n\n\n608\nUkraine\n2021\n413110.0\n16.7\n71.3\n32924000.0\n1.5\n121.7\n76.5\n-0.4\n10.9\n0.0\n0.2\n3.4\n-1.1\n-0.3\n91.1\n84.7\n15.1\n20539091.0\n5.3\n-0.9\n44298640.0\n13397238.0\n-1.3\n-0.6\n69.8\n1.0\n193.3\n1.6\n16.4\n1.982900e+10\n43.3\n-0.8\n1.450520e+10\n1.449359e+10\n6.751136e+08\n316.4\n9.296944e+11\n1.997659e+11\n60.0\nECS\nUMC\n\n\n\n\n609 rows × 43 columns"
  },
  {
    "objectID": "analysis/Final_project.html#data-preparation-for-modeling",
    "href": "analysis/Final_project.html#data-preparation-for-modeling",
    "title": "Analysis",
    "section": "Data preparation for modeling",
    "text": "Data preparation for modeling\nSplit the refined dataset dataForRf into two subsets: 70% for training (train_set) and 30% for testing (test_set). The random_state=42 ensures reproducibility, allowing the same split to be generated each time.\n\n\nCode\n# Split the data 70/30\ntrain_set, test_set = train_test_split(dataForRf, test_size=0.3, random_state=42)\n\n\nDefine the target variable for the model, which is “Deforestation.” The Deforestation column is extracted separately from the training (y_train) and testing (y_test) datasets.\n\n\nCode\n# the target labels: log of Deforestation\ny_train = train_set[\"Deforestation\"]\ny_test = test_set[\"Deforestation\"]\n\n\nPrepare the features for modeling by separating them into numerical and categorical variables. First, the target variable Deforestation is dropped from the dataset (dropDefo) to focus only on predictors. The remaining columns are divided based on their data type: num_cols contains numerical features, and cat_cols contains categorical features.\n\n\nCode\ndropDefo = dataForRf.drop(columns=[\"Deforestation\"])\n\n# Divide data by type\nnum_cols = sorted(dropDefo.select_dtypes(include=['int64', 'float64']).columns.tolist())\ncat_cols = sorted(dropDefo.select_dtypes(include=['object']).columns.tolist())\n\nprint(f'There are {len(cat_cols)} categorical variables')\nprint(f'There are {len(num_cols)} numerical variables')\n\n\nThere are 3 categorical variables\nThere are 39 numerical variables\n\n\nSet up a preprocessing pipeline using a ColumnTransformer to handle both numerical and categorical features. Numerical columns (num_cols) are scaled with StandardScaler to normalize their values, while categorical columns (cat_cols) are encoded into binary format using OneHotEncoder, which creates a new binary column for each unique category. The processed feature sets, X_train and X_test, are extracted from the training and testing datasets.\n\n\nCode\n# Set up the column transformer with two transformers\n# ----&gt; Scale the numerical columns\n# ----&gt; One-hot encode the categorical columns\n\ntransformer = ColumnTransformer(\n    transformers=[\n        (\"num\", StandardScaler(), num_cols),\n        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n    ]\n)\n\nX_train = train_set[num_cols + cat_cols]\nX_test = test_set[num_cols + cat_cols]"
  },
  {
    "objectID": "analysis/Final_project.html#pipeline",
    "href": "analysis/Final_project.html#pipeline",
    "title": "Analysis",
    "section": "Pipeline",
    "text": "Pipeline\nInitialize a machine learning pipeline combining data preprocessing and modeling. The transformer handles feature preprocessing (scaling numerical features and one-hot encoding categorical features), while the RandomForestRegressor is the chosen model for regression tasks.\n\n\nCode\n# Initialize the pipeline\npipe = make_pipeline(\n    transformer, RandomForestRegressor(n_estimators=10,\n                                       random_state=42)\n)"
  },
  {
    "objectID": "analysis/Final_project.html#base-random-forest-model",
    "href": "analysis/Final_project.html#base-random-forest-model",
    "title": "Analysis",
    "section": "Base Random Forest Model",
    "text": "Base Random Forest Model\nTrain the machine learning pipeline by fitting it to the training data (train_set) and the target labels (y_train). The pipeline automatically applies preprocessing (scaling and encoding) to the features and then trains the RandomForestRegressor model on the processed data.\n\n\nCode\n# Fit the training set\npipe.fit(train_set, y_train);\n\n\nEvaluate the performance of the trained pipeline on the testing dataset. The pipe.score method computes the R² (coefficient of determination) score, which measures how well the model’s predictions match the actual target values (y_test). An R² score close to 1 indicates a strong predictive performance, while lower values suggest areas for improvement.\n\n\nCode\n# What's the test score?\npipe.score(test_set, y_test)\n\n\n0.6748279503793474\n\n\n\n\nCode\ntestscore1 = pipe.score(test_set, y_test)"
  },
  {
    "objectID": "analysis/Final_project.html#feature-importance",
    "href": "analysis/Final_project.html#feature-importance",
    "title": "Analysis",
    "section": "Feature importance",
    "text": "Feature importance\nFeature importance is computed to identify the most significant variables contributing to deforestation.\nRetrieve the names of the transformed features after one-hot encoding. The one-hot encoder (ohe) within the pipeline is accessed to obtain the generated binary columns (ohe_cols) for categorical variables. These are combined with the original numerical column names (num_cols) to create a comprehensive list of feature names (features).\n\n\nCode\n# The one-hot step\nohe = transformer.named_transformers_['cat']\n\n# One column for each category type!\nohe_cols = ohe.get_feature_names_out()\n\n# Full list of columns is numerical + one-hot\nfeatures = num_cols + list(ohe_cols)\n\n\nCalculate the importance of each feature in the RandomForestRegressor. The trained random forest model is accessed from the pipeline (random_forest), and its feature_importances_ attribute provides the relative contribution of each feature to the model’s predictions. These importance values are combined with the feature names (features) into a DataFrame (importance).\n\n\nCode\nrandom_forest = pipe[\"randomforestregressor\"]\n\n# Create the dataframe with importances\nimportance = pd.DataFrame(\n    {\"Feature\": features, \"Importance\": random_forest.feature_importances_}\n)\n\n\n\nVisualization of feature importance\nThe importance DataFrame is merged with codeDescription to map each feature to its corresponding description. If a description is unavailable, the original feature name is retained. The resulting DataFrame, importanceResult, contains only the feature descriptions and their importance scores.\n\n\nCode\n# Change code to description\nimportanceResult = pd.merge(\n    importance,\n    codeDescription,\n    left_on='Feature',\n    right_on='Variable',\n    how='left'\n)\n\nimportanceResult = importanceResult.drop(columns=['Variable'])\nimportanceResult['Description'] = importanceResult['Description'].fillna(importanceResult['Feature'])\nimportanceResult = importanceResult.drop(columns=['Feature'])\n\n\nVisualize the top 20 most important features in the Random Forest model using a bar chart. The importanceResult DataFrame is sorted by the Importance column in descending order, and the top 20 features are selected. Altair is used to create a bar chart where the x-axis represents feature importance, and the y-axis lists feature descriptions sorted by their importance. Tooltips provide additional detail, and the chart is styled with a clear title and appropriate dimensions.\n\n\nCode\n# Sort the data and select the top 50 features\ntop_features = importanceResult.sort_values(\"Importance\", ascending=False).round(5).head(20)\n\n# Create the Feature Importance plot using Altair\nfeature_importance_chart = alt.Chart(top_features).mark_bar().encode(\n    x=alt.X(\"Importance:Q\", title=\"Importance\"),\n    y=alt.Y(\"Description:N\", sort='-x', title=\"Descriptions\"),\n    tooltip=[\"Description:N\", \"Importance:Q\"]\n).properties(\n    title=\"Top 20 Feature Importance Plot\",\n    width=600,\n    height=400\n).configure_title(\n    fontSize=16,\n    anchor='middle'\n)\n\nfeature_importance_chart.show()\n\n\n\n\n\n\n\n\nEvaluate the pipeline’s performance using 3-fold cross-validation. The dataset is split into three subsets, and the model is trained and tested on different combinations of these subsets to calculate R² scores (scores). These scores measure how well the model explains the variance in the target variable. The mean (scores.mean()) and standard deviation (scores.std()) of the scores are calculated to summarize the model’s overall performance and consistency across the folds.\n\n\nCode\n# Run the 3-fold cross validation\nscores = cross_val_score(\n    pipe,\n    X_train,\n    y_train,\n    cv=3,\n)\n\n# Copy\nscores1 = scores\nscoresmean1 = scores.mean\nscoresstd1 = scores.std\n\n\n# Report\nprint(\"R^2 scores = \", scores)\nprint(\"Scores mean = \", scores.mean())\nprint(\"Score std dev = \", scores.std())\n\n\nR^2 scores =  [0.85363655 0.71871286 0.55555343]\nScores mean =  0.7093009488161712\nScore std dev =  0.12187377264188007"
  },
  {
    "objectID": "analysis/Final_project.html#gridsearchcv",
    "href": "analysis/Final_project.html#gridsearchcv",
    "title": "Analysis",
    "section": "GridSearchCV",
    "text": "GridSearchCV\nThe grid search systematically tests all combinations of the hyperparameters defined in param_grid by training the model with 3-fold cross-validation (cv=3) for each combination. The grid.fit method trains the pipeline (pipeGridSearch) on the training data (train_set, y_train) to identify the best-performing hyperparameter settings. The verbose=1 option provides progress updates during the search process.\n\n\nCode\n# Create the grid and use 3-fold CV\ngrid = GridSearchCV(pipeGridSearch, param_grid, cv=3, verbose=1)\n\n# Run the search\ngrid.fit(train_set, y_train)\n\n\nFitting 3 folds for each of 64 candidates, totalling 192 fits\n\n\nGridSearchCV(cv=3,\n             estimator=Pipeline(steps=[('columntransformer',\n                                        ColumnTransformer(transformers=[('num',\n                                                                         StandardScaler(),\n                                                                         ['AG.LND.AGRI.K2',\n                                                                          'AG.LND.AGRI.ZS',\n                                                                          'AG.LND.ARBL.HA',\n                                                                          'AG.LND.CROP.ZS',\n                                                                          'AG.LND.FRST.ZS',\n                                                                          'AG.PRD.CROP.XD',\n                                                                          'BG.GSR.NFSV.GD.ZS',\n                                                                          'BM.GSR.FCTY.CD',\n                                                                          'BM.GSR.TRVL.ZS',\n                                                                          'CC.EST',\n                                                                          'DT.DOD.DIMF.CD',\n                                                                          'DT.TDS.DECT.CD',\n                                                                          'DT.TDS.MLAT.CD',\n                                                                          'EN.POP.DNST...\n                                                                          'SL.TLF.TOTL.IN',\n                                                                          'SN.ITK.DEFC.ZS',\n                                                                          'SP.POP.GROW', ...]),\n                                                                        ('cat',\n                                                                         OneHotEncoder(handle_unknown='ignore'),\n                                                                         ['Country',\n                                                                          'incomeLevel',\n                                                                          'region'])])),\n                                       ('randomforestregressor',\n                                        RandomForestRegressor(random_state=42))]),\n             param_grid={'randomforestregressor__max_depth': [2, 5, 7, 9, 13,\n                                                              21, 33, 51],\n                         'randomforestregressor__n_estimators': [5, 10, 15, 20,\n                                                                 30, 50, 100,\n                                                                 200]},\n             verbose=1)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.GridSearchCV?Documentation for GridSearchCViFittedGridSearchCV(cv=3,\n             estimator=Pipeline(steps=[('columntransformer',\n                                        ColumnTransformer(transformers=[('num',\n                                                                         StandardScaler(),\n                                                                         ['AG.LND.AGRI.K2',\n                                                                          'AG.LND.AGRI.ZS',\n                                                                          'AG.LND.ARBL.HA',\n                                                                          'AG.LND.CROP.ZS',\n                                                                          'AG.LND.FRST.ZS',\n                                                                          'AG.PRD.CROP.XD',\n                                                                          'BG.GSR.NFSV.GD.ZS',\n                                                                          'BM.GSR.FCTY.CD',\n                                                                          'BM.GSR.TRVL.ZS',\n                                                                          'CC.EST',\n                                                                          'DT.DOD.DIMF.CD',\n                                                                          'DT.TDS.DECT.CD',\n                                                                          'DT.TDS.MLAT.CD',\n                                                                          'EN.POP.DNST...\n                                                                          'SL.TLF.TOTL.IN',\n                                                                          'SN.ITK.DEFC.ZS',\n                                                                          'SP.POP.GROW', ...]),\n                                                                        ('cat',\n                                                                         OneHotEncoder(handle_unknown='ignore'),\n                                                                         ['Country',\n                                                                          'incomeLevel',\n                                                                          'region'])])),\n                                       ('randomforestregressor',\n                                        RandomForestRegressor(random_state=42))]),\n             param_grid={'randomforestregressor__max_depth': [2, 5, 7, 9, 13,\n                                                              21, 33, 51],\n                         'randomforestregressor__n_estimators': [5, 10, 15, 20,\n                                                                 30, 50, 100,\n                                                                 200]},\n             verbose=1) best_estimator_: PipelinePipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num', StandardScaler(),\n                                                  ['AG.LND.AGRI.K2',\n                                                   'AG.LND.AGRI.ZS',\n                                                   'AG.LND.ARBL.HA',\n                                                   'AG.LND.CROP.ZS',\n                                                   'AG.LND.FRST.ZS',\n                                                   'AG.PRD.CROP.XD',\n                                                   'BG.GSR.NFSV.GD.ZS',\n                                                   'BM.GSR.FCTY.CD',\n                                                   'BM.GSR.TRVL.ZS', 'CC.EST',\n                                                   'DT.DOD.DIMF.CD',\n                                                   'DT.TDS.DECT.CD',\n                                                   'DT.TDS.MLAT.CD',\n                                                   'EN.POP.DNST', 'FP.CPI.TOTL',\n                                                   'GC.XPN.TRFT...\n                                                   'NY.GDP.FRST.RT.ZS',\n                                                   'NY.GDP.MKTP.CD',\n                                                   'NY.GDP.MKTP.KD.ZG',\n                                                   'PV.EST', 'RQ.EST',\n                                                   'SE.PRM.ENRR', 'SE.SEC.ENRR',\n                                                   'SL.AGR.EMPL.ZS',\n                                                   'SL.TLF.TOTL.IN',\n                                                   'SN.ITK.DEFC.ZS',\n                                                   'SP.POP.GROW', ...]),\n                                                 ('cat',\n                                                  OneHotEncoder(handle_unknown='ignore'),\n                                                  ['Country', 'incomeLevel',\n                                                   'region'])])),\n                ('randomforestregressor',\n                 RandomForestRegressor(max_depth=13, n_estimators=50,\n                                       random_state=42))]) columntransformer: ColumnTransformer?Documentation for columntransformer: ColumnTransformerColumnTransformer(transformers=[('num', StandardScaler(),\n                                 ['AG.LND.AGRI.K2', 'AG.LND.AGRI.ZS',\n                                  'AG.LND.ARBL.HA', 'AG.LND.CROP.ZS',\n                                  'AG.LND.FRST.ZS', 'AG.PRD.CROP.XD',\n                                  'BG.GSR.NFSV.GD.ZS', 'BM.GSR.FCTY.CD',\n                                  'BM.GSR.TRVL.ZS', 'CC.EST', 'DT.DOD.DIMF.CD',\n                                  'DT.TDS.DECT.CD', 'DT.TDS.MLAT.CD',\n                                  'EN.POP.DNST', 'FP.CPI.TOTL',\n                                  'GC.XPN.TRFT.CN', 'GE.EST', 'NV.AGR.TOTL.ZS',\n                                  'NY.ADJ.DFOR.CD', 'NY.GDP.FRST.RT.ZS',\n                                  'NY.GDP.MKTP.CD', 'NY.GDP.MKTP.KD.ZG',\n                                  'PV.EST', 'RQ.EST', 'SE.PRM.ENRR',\n                                  'SE.SEC.ENRR', 'SL.AGR.EMPL.ZS',\n                                  'SL.TLF.TOTL.IN', 'SN.ITK.DEFC.ZS',\n                                  'SP.POP.GROW', ...]),\n                                ('cat', OneHotEncoder(handle_unknown='ignore'),\n                                 ['Country', 'incomeLevel', 'region'])]) num['AG.LND.AGRI.K2', 'AG.LND.AGRI.ZS', 'AG.LND.ARBL.HA', 'AG.LND.CROP.ZS', 'AG.LND.FRST.ZS', 'AG.PRD.CROP.XD', 'BG.GSR.NFSV.GD.ZS', 'BM.GSR.FCTY.CD', 'BM.GSR.TRVL.ZS', 'CC.EST', 'DT.DOD.DIMF.CD', 'DT.TDS.DECT.CD', 'DT.TDS.MLAT.CD', 'EN.POP.DNST', 'FP.CPI.TOTL', 'GC.XPN.TRFT.CN', 'GE.EST', 'NV.AGR.TOTL.ZS', 'NY.ADJ.DFOR.CD', 'NY.GDP.FRST.RT.ZS', 'NY.GDP.MKTP.CD', 'NY.GDP.MKTP.KD.ZG', 'PV.EST', 'RQ.EST', 'SE.PRM.ENRR', 'SE.SEC.ENRR', 'SL.AGR.EMPL.ZS', 'SL.TLF.TOTL.IN', 'SN.ITK.DEFC.ZS', 'SP.POP.GROW', 'SP.POP.TOTL', 'SP.RUR.TOTL', 'SP.RUR.TOTL.ZG', 'SP.URB.GROW', 'SP.URB.TOTL.IN.ZS', 'TM.VAL.AGRI.ZS.UN', 'TM.VAL.MRCH.XD.WD', 'TX.VAL.AGRI.ZS.UN', 'year'] StandardScaler?Documentation for StandardScalerStandardScaler() cat['Country', 'incomeLevel', 'region'] OneHotEncoder?Documentation for OneHotEncoderOneHotEncoder(handle_unknown='ignore') RandomForestRegressor?Documentation for RandomForestRegressorRandomForestRegressor(max_depth=13, n_estimators=50, random_state=42) \n\n\ngrid.best_estimator_: Displays the pipeline with the best combination of hyperparameters, which achieved the highest performance during cross-validation. grid.best_params_: Shows the specific hyperparameter values (e.g., n_estimators and max_depth) that resulted in the best model performance.\n\n\nCode\n# The best estimator\ngrid.best_estimator_\n\n# The best hyper parameters\ngrid.best_params_\n\n\n{'randomforestregressor__max_depth': 13,\n 'randomforestregressor__n_estimators': 50}\n\n\nThe model (best_model) predicts the target values (y_pred) for the test set (X_test), and its performance is measured using the R² score, which assesses how well the model explains the variance in the actual target values (y_test). The results include the average cross-validation score during training (grid.best_score_) and the R² score on the testing data.\n\n\nCode\n# Compute recall score on the testing set using the best model\nbest_model = grid.best_estimator_\ny_pred = best_model.predict(X_test)\nsearch_score = r2_score(y_test, y_pred)\ntestscore2 = search_score\n\nprint(f'The best model achieves an average cross-validation score of {grid.best_score_*100:.2f}%')\nprint(f'The best model achieves a r2 score of {search_score*100:.2f}% on the testing data')\n\n\nThe best model achieves an average cross-validation score of 73.78%\nThe best model achieves a r2 score of 67.43% on the testing data\n\n\n3-fold cross-validation to evaluate the performance of the pipeline (pipeGridSearch) on the training data (X_train and y_train). It splits the data into three subsets, trains the model on two subsets, and tests it on the third, repeating this process for all folds. The R² scores from each fold are recorded, and their mean and standard deviation are calculated to summarize the model’s overall performance and consistency.\n\n\nCode\n# Run the 3-fold cross validation\nscores = cross_val_score(\n    pipeGridSearch,\n    X_train,\n    y_train,\n    cv=3,\n)\n\n# Copy\nscores2 = scores\nscoresmean2 = scores.mean\nscoresstd2 = scores.std\n\n# Report\nprint(\"R^2 scores = \", scores)\nprint(\"Scores mean = \", scores.mean())\nprint(\"Score std dev = \", scores.std())\n\n\nR^2 scores =  [0.86553356 0.74053747 0.56055631]\nScores mean =  0.7222091138420561\nScore std dev =  0.1251791455131474\n\n\n\nVisualization of accuracy comparison\nCompare the performance of the initial and optimized models by summarizing their R² scores from cross-validation and testing. The scores for each fold, along with the mean and test scores, are recorded for both models. The data is structured into a DataFrame (slope_df) to prepare for visualization, highlighting the performance improvements achieved through hyperparameter optimization using GridSearchCV.\n\n\nCode\n# Comparing before and after optimization using GridSearchCV\n# Data for initial model\ninitial_cv_scores = scores1\ninitial_mean = scoresmean1()\ninitial_std = scoresstd1()\ninitial_test_score = testscore1\n\n# Data for optimized model\noptimized_cv_scores = scores2\noptimized_mean = scoresmean2()\noptimized_std = scoresstd2()\noptimized_test_score = testscore2\n\n# Data for the slope graph\nmetrics = ['Fold 1', 'Fold 2', 'Fold 3', 'Mean', 'Test Score']\ninitial_scores = initial_cv_scores.tolist() + [initial_mean, initial_test_score]\noptimized_scores = optimized_cv_scores.tolist() + [optimized_mean, optimized_test_score]\n\n# Prepare the data for the slope graph\nslope_data = {\n    'Metric': metrics * 2,  # Repeat metrics for 'Initial' and 'Optimized'\n    'Score': initial_scores + optimized_scores,\n    'Model': ['Initial'] * len(metrics) + ['Optimized'] * len(metrics)\n}\n\n# Convert to DataFrame\nslope_df = pd.DataFrame(slope_data)\n\n\nVisualize the comparison between the initial and optimized models using a slope graph created with Altair. The chart displays R² scores for each metric (e.g., folds, mean, and test score) as lines connecting the initial and optimized models, making it easy to observe performance improvements. Custom colors are used to differentiate metrics, and tooltips provide detailed information on scores and models.\n\n\nCode\n# Create chart\n# Define custom colors for each metric\ncustom_colors = {\n    'Fold 1': '#82C574',\n    'Fold 2': '#EB9E42',\n    'Fold 3': '#DF7068',\n    'Mean': '#7DC1DD',\n    'Test Score': '#3F597C'\n}\n\n# Create the slope graph\nslope_chart = alt.Chart(slope_df).mark_line(point=alt.MarkConfig(size=100)).encode(\n    x=alt.X('Model:N', title='', axis=alt.Axis(labels=True, labelAngle=0)),\n    y=alt.Y('Score:Q', title='R² Score', scale=alt.Scale(domain=[0.5, 1])),\n    color=alt.Color('Metric:N', scale=alt.Scale(domain=list(custom_colors.keys()), range=list(custom_colors.values()))),\n    detail='Metric:N',\n    tooltip=['Metric:N', 'Score:Q', 'Model:N']\n).properties(\n    title=\"R² Score: Initial vs Optimized (GridSearchCV) Model\",\n    width=400,\n    height=300\n).configure_title(\n    fontSize=16,\n    anchor='middle'\n).configure_axis(\n    labelFontSize=12,\n    titleFontSize=14\n)\n\nslope_chart.show()"
  },
  {
    "objectID": "analysis/Final_project.html#comparison-of-tested-vs.-predicted-deforestation",
    "href": "analysis/Final_project.html#comparison-of-tested-vs.-predicted-deforestation",
    "title": "Analysis",
    "section": "Comparison of Tested vs. Predicted Deforestation",
    "text": "Comparison of Tested vs. Predicted Deforestation\n\nVisualization of y test and y prediction\nAltair visualizations are created to compare actual deforestation trends (y_test) with model predictions (y_pred). A shared brush selection allows users to focus on specific countries.\nA new DataFrame, predVis, is created to store predictions along with associated metadata, such as year, Country, and region. The region_full column maps region abbreviations to their full names for clarity. Similarly, the actual deforestation values are combined with their corresponding metadata in mergeXYTest.\n\n\nCode\n# Visualization: Comparing between actual vs prediction\npredVis = pd.DataFrame({'Predictions': y_pred})\npredVis['year'] = X_test['year'].reset_index(drop=True)\npredVis['Country'] = X_test['Country'].reset_index(drop=True)\npredVis['region'] = X_test['region'].reset_index(drop=True)\npredVis['region_full'] = predVis['region'].map(region_mapping)\n\ndfYTest = pd.DataFrame(y_test)\nX_test_index = X_test.reset_index()\ndfYTest = dfYTest.reset_index()\nmergeXYTest = pd.merge(dfYTest, X_test_index, on='index')\nmergeXYTest = mergeXYTest[['Deforestation', 'Country', 'year', 'region']]\nmergeXYTest['region_full'] = mergeXYTest['region'].map(region_mapping)\n\n\nCreate a side-by-side comparison of observed (y_test) and predicted (y_pred) deforestation trends using Altair. Two bar charts are generated: one for reported deforestation (mergeXYTest) and another for predicted values (predVis). Both charts are grouped by year and colored by regions, with custom colors and tooltips providing additional details. A shared brush selection allows users to click on a specific country to highlight its data in both charts simultaneously. The charts are combined horizontally to visualize actual versus predicted trends side-by-side.\n\n\nCode\n# Define custom colors\ncustomColor = ['#7DC1DD', '#EB9E42', '#DF7068', '#82C574', '#82888D', '#3F597C']\n\n# Shared brush selection for both charts\nshared_brush = alt.selection_point(fields=['Country'], on='click', name='shared')\n\n# Plot 1: Reported Deforestation\ndeforestation_chart = alt.Chart(mergeXYTest).mark_bar(stroke='white', strokeWidth=0.5).encode(\n    x=alt.X('year:O', title='Year'),\n    y=alt.Y('sum(Deforestation):Q', title='Change in Forest Area, sq. km (Negative = forest loss)'),\n    color=alt.condition(\n        shared_brush,\n        alt.Color(\"region_full:N\", scale=alt.Scale(range=customColor), legend=alt.Legend(title=\"Region\", orient=\"bottom-left\")),\n        alt.value('lightgray')\n    ),\n    tooltip=['Country', 'year', 'Deforestation', 'region_full']\n).add_params(\n    shared_brush\n).properties(\n    title='Observed Deforestation (y_test)',\n    width=400,\n    height=300\n)\n\n# Plot 2: Predicted Deforestation\npredDefoChart = alt.Chart(predVis).mark_bar(stroke='white', strokeWidth=0.5).encode(\n    x=alt.X('year:O', title='Year'),\n    y=alt.Y('sum(Predictions):Q', title='Change in Forest Area, sq. km (Negative = forest loss)'),\n    color=alt.condition(\n        shared_brush,\n        alt.Color(\"region_full:N\", scale=alt.Scale(range=customColor), legend=alt.Legend(title=\"Region\", orient=\"bottom-left\")),\n        alt.value('lightgray')\n    ),\n    tooltip=['Country', 'year', 'Predictions', 'region_full']\n).add_params(\n    shared_brush\n).properties(\n    title='Predicted Deforestation (y_pred)',\n    width=400,\n    height=300\n)\n\n# Combine charts horizontally\ncombined_chart = alt.hconcat(\n    deforestation_chart,\n    predDefoChart\n).properties(\n    title=\"Comparison\"\n).configure_legend(\n    orient='bottom-left',\n    titleFontSize=12,\n    labelFontSize=10,\n    fillColor='white'\n).configure_title(\n    fontSize=16,\n    anchor='middle',\n    color='black'\n)\n\n# Show the combined chart\ncombined_chart"
  },
  {
    "objectID": "analysis/Final_project.html#residual-analysis",
    "href": "analysis/Final_project.html#residual-analysis",
    "title": "Analysis",
    "section": "Residual analysis",
    "text": "Residual analysis\nResiduals (differences between actual and predicted values) are analyzed to check for systematic biases in the model.\nThe residuals are stored in a new DataFrame, yResidual, providing insight into the errors made by the model. A copy of this DataFrame, yResidualVis, is created for visualization, and it includes the predicted values alongside the residuals to help analyze patterns and identify systematic biases in the model’s predictions.\n\n\nCode\n# Calculate residuals\nyResidual = pd.DataFrame()\nyResidual['Residuals'] = mergeXYTest['Deforestation'] - predVis['Predictions']\n\n# Create dataframe for visualization\nyResidualVis = yResidual.copy()\nyResidualVis['Predictions'] = predVis['Predictions']\n\n\n\nVisualization of residual\nCreate a residual plot to evaluate the performance of the regression model. Using Seaborn’s scatterplot, it plots predicted values (Predictions) on the x-axis and residuals (Residuals) on the y-axis. A horizontal dashed line at y=0 is added as a reference, showing where residuals would indicate perfect predictions. The plot is styled with titles, labels, and a grid for clarity. Randomly scattered residuals around the zero line suggest the model performs well.\n\n\nCode\n# Create a scatter plot for residuals\nfig, axes = plt.subplots(1, 1, figsize=(6, 4))\n\n# Create a scatter plot of residuals\nsns.scatterplot(\n    data=yResidualVis,\n    x='Predictions',  # X-axis as index of residuals\n    y='Residuals',  # Residuals on the Y-axis\n    color='#DF7068',\n    ax=axes\n)\naxes.axhline(0, color='#3F597C', linestyle='--', linewidth=1)  # Add a horizontal line at 0\naxes.set_title('Residual Plot', fontsize=11)\naxes.set_xlabel('Predictions', fontsize=11)\naxes.set_ylabel('Residuals', fontsize=11)\naxes.grid(True)\n\n# Show the plot\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "analysis/index.html",
    "href": "analysis/index.html",
    "title": "Analysis",
    "section": "",
    "text": "Analysis\nThis section includes examples of technical analysis done using Jupyter notebooks. Each sub-section highlights different types of analyses and visualizations. In particular, it highlights that we can easily publish interactive visualizations produced with packages such as hvPlot, altair, or Folium, without losing any of the interactive features.\nOn this page, you might want to share more introductory or background information about the analyses to help guide the reader."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Re-rethinking the causes of deforestation: does the theory evolve?",
    "section": "",
    "text": "Another football field of forest will be lost in:\n\n\n   \n\n6\n\n\n\n\n\nForest loss since you opened this page: 0 acres\n\n\n\n\n\ninformation"
  },
  {
    "objectID": "faq.html",
    "href": "faq.html",
    "title": "Frequently Asked Question",
    "section": "",
    "text": "Why does the number of acres of forest loss keep counting even when I reload the page? Why doesn’t it reset to 0?\nThe forest loss counter stores its data in your browser’s local storage. If you want to reset it to 0, you can clear your browser cache. Remember that stopping deforestation requires consistent efforts—just like clearing your cache requires action on your part."
  }
]